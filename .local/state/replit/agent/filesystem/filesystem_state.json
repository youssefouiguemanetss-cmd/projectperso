{"file_contents":{"static/style.css":{"content":"/* Custom styles for TSS Gmail Access */\n\n/* Enhanced hover effects */\n.email-row {\n    transition: all 0.2s ease-in-out;\n}\n\n.email-row:hover {\n    background-color: #f9fafb;\n    transform: translateY(-1px);\n    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n}\n\n/* Email item enhanced styling */\n.email-item {\n    transition: all 0.2s ease;\n    border-left: 3px solid transparent;\n}\n\n.email-item:hover {\n    border-left-color: #3b82f6;\n    background-color: #fafbff;\n    transform: translateX(2px);\n}\n\n.email-item .new-badge {\n    animation: newEmailBadge 1s ease infinite;\n}\n\n@keyframes newEmailBadge {\n    0%, 100% { transform: scale(1); }\n    50% { transform: scale(1.05); }\n}\n\n/* Custom focus styles for better accessibility */\nselect:focus,\ninput:focus {\n    outline: none;\n    box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1);\n}\n\n/* Smooth transitions for form elements */\nselect,\ninput {\n    transition: all 0.2s ease-in-out;\n}\n\n/* Custom scrollbar for table */\n.overflow-x-auto::-webkit-scrollbar {\n    height: 6px;\n}\n\n.overflow-x-auto::-webkit-scrollbar-track {\n    background: #f1f5f9;\n    border-radius: 3px;\n}\n\n.overflow-x-auto::-webkit-scrollbar-thumb {\n    background: #cbd5e1;\n    border-radius: 3px;\n}\n\n.overflow-x-auto::-webkit-scrollbar-thumb:hover {\n    background: #94a3b8;\n}\n\n/* Loading animation for form submission */\n.loading {\n    position: relative;\n    overflow: hidden;\n}\n\n.loading::after {\n    content: '';\n    position: absolute;\n    top: 0;\n    left: -100%;\n    width: 100%;\n    height: 100%;\n    background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.4), transparent);\n    animation: loading 1.5s infinite;\n}\n\n@keyframes loading {\n    0% { left: -100%; }\n    100% { left: 100%; }\n}\n\n/* Responsive text truncation */\n@media (max-width: 640px) {\n    .max-w-xs {\n        max-width: 120px;\n    }\n    \n    .max-w-md {\n        max-width: 150px;\n    }\n}\n\n/* Enhanced badge styles */\n.inline-flex.items-center {\n    font-weight: 600;\n    letter-spacing: 0.025em;\n}\n\n/* Table header enhancements */\nthead th {\n    font-weight: 600;\n    letter-spacing: 0.05em;\n}\n\n/* Card shadow enhancements */\n.shadow-md {\n    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);\n}\n\n.shadow-sm {\n    box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);\n}\n\n/* Custom focus ring for better accessibility */\n.focus\\:ring-2:focus {\n    box-shadow: 0 0 0 2px var(--tw-ring-color);\n}\n\n/* Animated icons */\n.fas {\n    transition: transform 0.2s ease-in-out;\n}\n\n.hover\\:transform:hover .fas {\n    transform: scale(1.1);\n}\n\n/* Custom button hover effects */\nbutton:hover,\n.btn:hover {\n    transform: translateY(-1px);\n    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);\n}\n\n/* Gradient text effect for title */\n.text-gradient {\n    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n    -webkit-background-clip: text;\n    -webkit-text-fill-color: transparent;\n    background-clip: text;\n}\n\n/* Custom alert animations */\n.alert {\n    animation: slideInFromTop 0.3s ease-out;\n}\n\n@keyframes slideInFromTop {\n    0% {\n        transform: translateY(-20px);\n        opacity: 0;\n    }\n    100% {\n        transform: translateY(0);\n        opacity: 1;\n    }\n}\n\n/* Enhanced table styling */\ntbody tr {\n    border-bottom: 1px solid #e5e7eb;\n}\n\ntbody tr:last-child {\n    border-bottom: none;\n}\n\n/* Custom tooltip styles */\n[title]:hover::before {\n    content: attr(title);\n    position: absolute;\n    background: #374151;\n    color: white;\n    padding: 4px 8px;\n    border-radius: 4px;\n    font-size: 12px;\n    white-space: nowrap;\n    z-index: 1000;\n    transform: translateY(-100%);\n    margin-top: -8px;\n}\n\n/* Loading spinner for async operations */\n.spinner {\n    border: 2px solid #f3f4f6;\n    border-top: 2px solid #3b82f6;\n    border-radius: 50%;\n    width: 20px;\n    height: 20px;\n    animation: spin 1s linear infinite;\n    display: inline-block;\n    margin-right: 8px;\n}\n\n@keyframes spin {\n    0% { transform: rotate(0deg); }\n    100% { transform: rotate(360deg); }\n}\n\n/* Mobile optimizations */\n@media (max-width: 768px) {\n    .container {\n        padding-left: 1rem;\n        padding-right: 1rem;\n    }\n    \n    .text-4xl {\n        font-size: 2rem;\n    }\n    \n    .grid-cols-3 {\n        grid-template-columns: 1fr;\n    }\n}\n\n/* Search input styling */\ninput[type=\"text\"] {\n    background-image: url(\"data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' fill='none' viewBox='0 0 24 24' stroke='%236b7280'%3e%3cpath stroke-linecap='round' stroke-linejoin='round' stroke-width='2' d='M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z'/%3e%3c/svg%3e\");\n    background-position: right 0.75rem center;\n    background-repeat: no-repeat;\n    background-size: 1.25em 1.25em;\n    padding-right: 3rem;\n}\n\n/* Enhanced focus states for inputs */\ninput:focus-visible {\n    outline: 2px solid #3b82f6;\n    outline-offset: 2px;\n}\n\n/* Auto-refresh indicator animation */\n.auto-refresh-indicator {\n    animation: pulse 2s infinite;\n}\n\n@keyframes pulse {\n    0%, 100% { opacity: 1; }\n    50% { opacity: 0.5; }\n}\n\n/* Filter section styling */\n.grid .flex.flex-col input,\n.grid .flex.flex-col select {\n    font-size: 0.9rem;\n}\n\n.grid .flex.flex-col label {\n    font-size: 0.85rem;\n    color: #374151;\n}\n\n/* Enhanced form spacing */\n.space-y-4 > * + * {\n    margin-top: 1rem;\n}\n\n/* Filter active state */\ninput[type=\"text\"]:not(:placeholder-shown) {\n    border-color: #3b82f6;\n    box-shadow: 0 0 0 1px #3b82f6;\n}\n\n/* Email counter styling */\n.text-blue-600 {\n    font-weight: 600;\n}\n\n/* Loading overlay for form */\n.loading {\n    position: relative;\n    pointer-events: none;\n    opacity: 0.7;\n}\n\n.loading::before {\n    content: '';\n    position: absolute;\n    top: 0;\n    left: 0;\n    right: 0;\n    bottom: 0;\n    background: rgba(255, 255, 255, 0.8);\n    z-index: 10;\n    border-radius: 0.5rem;\n}\n\n.loading::after {\n    content: '';\n    position: absolute;\n    top: 50%;\n    left: 50%;\n    transform: translate(-50%, -50%);\n    width: 2rem;\n    height: 2rem;\n    border: 3px solid #e5e7eb;\n    border-top: 3px solid #3b82f6;\n    border-radius: 50%;\n    animation: spin 1s linear infinite;\n    z-index: 11;\n}\n\n/* Gmail Account Cards Styling */\n.gmail-account-card {\n    transition: all 0.3s ease;\n    position: relative;\n    overflow: hidden;\n}\n\n.gmail-account-card::before {\n    content: '';\n    position: absolute;\n    top: 0;\n    left: -100%;\n    width: 100%;\n    height: 100%;\n    background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.4), transparent);\n    transition: left 0.5s;\n}\n\n.gmail-account-card:hover::before {\n    left: 100%;\n}\n\n.gmail-account-card:hover {\n    transform: translateY(-2px);\n    box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);\n}\n\n.gmail-account-card:active {\n    transform: translateY(0px);\n    transition: transform 0.1s;\n}\n\n/* Enhanced profile icon animations */\n.gmail-account-card .fa-user {\n    transition: transform 0.3s ease;\n}\n\n.gmail-account-card:hover .fa-user {\n    transform: scale(1.1) rotate(5deg);\n}\n\n/* Category count badges enhanced styling */\n.category-tab span {\n    transition: all 0.2s ease;\n    min-width: 1.5rem;\n    text-align: center;\n}\n\n.category-tab:hover span {\n    transform: scale(1.1);\n}\n\n.category-tab.active span {\n    animation: countPulse 0.5s ease;\n}\n\n@keyframes countPulse {\n    0% { transform: scale(1); }\n    50% { transform: scale(1.2); }\n    100% { transform: scale(1); }\n}\n\n/* Enhanced notification styling */\n#new-email-notification {\n    animation: slideInRight 0.3s ease, pulse 2s infinite 0.3s;\n    backdrop-filter: blur(10px);\n    border: 1px solid rgba(255, 255, 255, 0.2);\n}\n\n@keyframes slideInRight {\n    0% {\n        transform: translateX(100%);\n        opacity: 0;\n    }\n    100% {\n        transform: translateX(0);\n        opacity: 1;\n    }\n}\n\n/* Responsive improvements for Gmail cards */\n@media (max-width: 640px) {\n    .gmail-account-card {\n        padding: 0.75rem;\n    }\n    \n    .gmail-account-card .w-12 {\n        width: 2.5rem;\n        height: 2.5rem;\n    }\n    \n    .gmail-account-card .text-lg {\n        font-size: 0.875rem;\n    }\n}\n\n/* Enhanced grid responsiveness */\n@media (min-width: 1024px) {\n    #gmail-accounts-grid {\n        grid-template-columns: repeat(4, 1fr);\n    }\n}\n\n@media (min-width: 1280px) {\n    #gmail-accounts-grid {\n        grid-template-columns: repeat(5, 1fr);\n    }\n}\n\n/* Status indicator animations */\n.gmail-account-card .fa-circle {\n    animation: statusBlink 2s infinite;\n}\n\n@keyframes statusBlink {\n    0%, 50% { opacity: 1; }\n    25%, 75% { opacity: 0.6; }\n}\n\n/* Enhanced button interactions */\n#new-email-notification button:hover {\n    background-color: rgba(255, 255, 255, 0.2);\n    border-radius: 50%;\n    transform: scale(1.1);\n}\n\n/* Improved focus states for accessibility */\n.gmail-account-card:focus {\n    outline: 2px solid #3b82f6;\n    outline-offset: 2px;\n}\n\n.category-tab:focus {\n    outline: 2px solid #3b82f6;\n    outline-offset: -2px;\n}\n","path":null,"size_bytes":8898,"size_tokens":null},"connection_manager.py":{"content":"import threading\nimport time\nimport imaplib\nimport email\nimport email.utils\nfrom email.header import decode_header\nfrom datetime import datetime, timezone\nimport logging\nimport json\nimport os\nfrom collections import defaultdict, Counter\n\nclass EntityBasedGmailManager:\n    \"\"\"Enhanced Gmail connection manager with smart monitoring and health management\"\"\"\n    \n    def __init__(self):\n        self.entity_connections = {}  # entity -> {account_key: connection_info}\n        self.active_entities = set()  # entities with at least one logged-in user\n        self.logged_users = defaultdict(set)  # entity -> set of user_ids\n        self.tssw_selected_accounts = {}  # user_id -> account_key (for TSSW users)\n        self.email_cache = {}  # account_key -> list of emails\n        self.update_callbacks = defaultdict(list)  # account_key -> list of callback functions\n        self.lock = threading.RLock()\n        self.all_accounts = {}  # account_key -> account_info (loaded from file)\n        \n        # Enhanced monitoring system\n        self.connection_stats = {}  # account_key -> stats (health, last_heartbeat, errors, etc.)\n        self.health_monitor_thread = None\n        self.health_monitor_stop = threading.Event()\n        self.rebuilding_connections = set()  # accounts currently being rebuilt\n        self.heartbeat_interval = 120  # Send heartbeat every 2 minutes\n        self.health_check_interval = 300  # Check health every 5 minutes\n        self.max_connection_age = 900  # Rebuild connections older than 15 minutes\n        \n        # Hybrid intelligent system\n        self.usage_analytics = {}  # Track usage patterns\n        self.warm_pool = set()  # Always-connected accounts (top 5 most used)\n        self.pre_connected_entities = set()  # Entities pre-connected based on patterns\n        self.usage_history_file = 'connection_usage_history.json'\n        self.max_warm_pool_size = 5\n        self.backup_connections = {}  # Backup connections for critical accounts\n        self.connection_retry_counts = defaultdict(int)  # Track retry attempts\n        self.max_retries = 3\n        \n        # Toggle button management system\n        self.manual_toggles = {}  # account_key -> {'state': 'on/off', 'toggled_by': user_id, 'toggle_time': timestamp}\n        self.forced_disconnects = set()  # accounts manually disconnected by TSSW\n        \n        # Load usage history and initialize intelligent pre-connections\n        self._load_usage_history()\n        self._initialize_intelligent_preconnections()\n        \n        # Start global health monitoring\n        self._start_health_monitoring()\n        \n        # Start auto-reconnect checker\n        self._start_auto_reconnect_checker()\n        \n        logging.info(\"Hybrid intelligent system initialized with smart monitoring and pre-connections\")\n    \n    def load_gmail_accounts(self):\n        \"\"\"Load Gmail accounts from gmailaccounts.txt file\"\"\"\n        accounts = {}\n        news_accounts = {}\n        try:\n            with open('gmailaccounts.txt', 'r', encoding='utf-8') as f:\n                for line_num, line in enumerate(f, 1):\n                    line = line.strip()\n                    if line and not line.startswith('#'):\n                        try:\n                            parts = line.split(',')\n                            if len(parts) >= 3:\n                                entity = parts[0].strip().upper()\n                                email_addr = parts[1].strip()\n                                app_password = parts[2].strip()\n                                is_news = len(parts) >= 4 and parts[3].strip().lower() == 'news'\n                                \n                                account_key = f\"{entity}_{email_addr}\"\n                                account_info = {\n                                    \"entity\": entity,\n                                    \"email\": email_addr,\n                                    \"app_password\": app_password,\n                                    \"display_name\": f\"{entity} - {email_addr}\",\n                                    \"is_news\": is_news\n                                }\n                                \n                                if is_news:\n                                    news_accounts[account_key] = account_info\n                                else:\n                                    accounts[account_key] = account_info\n                            else:\n                                logging.warning(f\"Invalid format in gmailaccounts.txt line {line_num}: {line}\")\n                        except Exception as e:\n                            logging.error(f\"Error parsing gmailaccounts.txt line {line_num}: {e}\")\n        except FileNotFoundError:\n            logging.error(\"gmailaccounts.txt file not found\")\n        except Exception as e:\n            logging.error(f\"Error reading gmailaccounts.txt: {e}\")\n        \n        with self.lock:\n            self.all_accounts = accounts\n            self.news_accounts = news_accounts\n        return accounts\n    \n    def get_news_accounts(self, user_entity):\n        \"\"\"Get news Gmail accounts accessible to a user based on their entity\"\"\"\n        user_entity = user_entity.upper()\n        \n        if not hasattr(self, 'news_accounts') or not self.news_accounts:\n            self.load_gmail_accounts()\n        \n        if user_entity == 'TSSW':\n            return self.news_accounts\n        else:\n            user_news_accounts = {}\n            for key, account in self.news_accounts.items():\n                if account['entity'] == user_entity:\n                    user_news_accounts[key] = account\n            return user_news_accounts\n    \n    def user_login(self, user_id, user_entity):\n        \"\"\"Handle user login with intelligent pre-connection and analytics\"\"\"\n        user_entity = user_entity.upper()\n        \n        with self.lock:\n            # Add user to logged users\n            self.logged_users[user_entity].add(user_id)\n            \n            # Record login for analytics\n            self._record_login_analytics(user_entity)\n            \n            # Handle TSSW special case - they don't auto-connect, wait for account selection\n            if user_entity == 'TSSW':\n                logging.info(f\"TSSW user {user_id} logged in - awaiting account selection\")\n                # Pre-warm TSSW connections based on their usage patterns\n                self._prewarm_tssw_connections(user_id)\n            else:\n                # Fast activation - entity likely already pre-connected\n                self._activate_entity_fast(user_entity)\n                logging.info(f\"User {user_id} from entity {user_entity} logged in (fast activation)\")\n    \n    def user_logout(self, user_id, user_entity):\n        \"\"\"Handle user logout - disconnect connections appropriately\"\"\"\n        user_entity = user_entity.upper()\n        \n        with self.lock:\n            # Handle TSSW logout - disconnect their selected account if needed\n            if user_entity == 'TSSW' and user_id in self.tssw_selected_accounts:\n                selected_account = self.tssw_selected_accounts[user_id]\n                selected_entity = selected_account.split('_')[0]\n                \n                # If this was the only connection to this account and no users from that entity are logged in\n                if (selected_entity != 'TSSW' and \n                    not self.logged_users.get(selected_entity) and\n                    selected_account in self.email_cache):\n                    self._close_connection(selected_account)\n                \n                # Remove from TSSW selections\n                del self.tssw_selected_accounts[user_id]\n            \n            # Remove user from logged users\n            if user_entity in self.logged_users:\n                self.logged_users[user_entity].discard(user_id)\n                \n                # If no users left in this entity, deactivate it\n                if not self.logged_users[user_entity]:\n                    self._deactivate_entity(user_entity)\n                    logging.info(f\"Last user from entity {user_entity} logged out - disconnecting accounts\")\n    \n    def get_user_accounts(self, user_entity):\n        \"\"\"Get Gmail accounts accessible to a user based on their entity\"\"\"\n        user_entity = user_entity.upper()\n        \n        # Ensure accounts are loaded\n        if not self.all_accounts:\n            self.load_gmail_accounts()\n        \n        if user_entity == 'TSSW':\n            # TSSW users can see all accounts\n            return self.all_accounts\n        else:\n            # Other users can only see accounts from their entity\n            user_accounts = {}\n            for key, account in self.all_accounts.items():\n                if account['entity'] == user_entity:\n                    user_accounts[key] = account\n            return user_accounts\n    \n    def get_emails(self, account_key):\n        \"\"\"Get cached emails for an account\"\"\"\n        with self.lock:\n            return self.email_cache.get(account_key, [])\n    \n    def connect_tssw_account(self, user_id, account_key):\n        \"\"\"Connect TSSW user to a specific account\"\"\"\n        with self.lock:\n            # Disconnect previous TSSW account selection if any\n            if user_id in self.tssw_selected_accounts:\n                old_account = self.tssw_selected_accounts[user_id]\n                self._disconnect_tssw_account(user_id, old_account)\n            \n            # Store new selection\n            self.tssw_selected_accounts[user_id] = account_key\n            \n            # Check if account is already connected\n            if account_key in self.email_cache:\n                logging.info(f\"TSSW user {user_id} using existing connection for {account_key}\")\n                return\n            \n            # Get account info\n            if not self.all_accounts:\n                self.load_gmail_accounts()\n            \n            if account_key not in self.all_accounts:\n                logging.error(f\"Account {account_key} not found\")\n                return\n            \n            account_info = self.all_accounts[account_key]\n            selected_entity = account_info['entity']\n            \n            # Check if entity has logged-in users (use existing connection)\n            if (selected_entity != 'TSSW' and \n                self.logged_users.get(selected_entity) and \n                selected_entity in self.active_entities):\n                logging.info(f\"TSSW user {user_id} using existing {selected_entity} entity connection for {account_key}\")\n                return\n            \n            # Create new connection for this specific account\n            self._start_single_connection(account_key, account_info)\n            logging.info(f\"TSSW user {user_id} created new connection for {account_key}\")\n    \n    def _disconnect_tssw_account(self, user_id, account_key):\n        \"\"\"Disconnect TSSW user from specific account if it's not being used by others\"\"\"\n        if account_key not in self.email_cache:\n            return\n        \n        account_info = self.all_accounts.get(account_key)\n        if not account_info:\n            return\n            \n        selected_entity = account_info['entity']\n        \n        # Don't disconnect if:\n        # 1. The entity has its own users logged in\n        # 2. Other TSSW users are using this account\n        # 3. It's a TSSW account and other TSSW users are logged in\n        if (selected_entity != 'TSSW' and self.logged_users.get(selected_entity)):\n            return\n        \n        if (selected_entity == 'TSSW' and \n            len([uid for uid, acc in self.tssw_selected_accounts.items() \n                 if acc == account_key and uid != user_id]) > 0):\n            return\n        \n        if len(self.logged_users.get('TSSW', set())) > 1:\n            # Check if other TSSW users are using this account\n            other_tssw_using = any(acc == account_key for uid, acc in self.tssw_selected_accounts.items() if uid != user_id)\n            if other_tssw_using:\n                return\n        \n        # Safe to disconnect\n        self._close_connection(account_key)\n        logging.info(f\"Disconnected TSSW account {account_key} for user {user_id}\")\n    \n    # Toggle Button System Methods\n    def toggle_account_connection(self, user_id, user_entity, account_key, force_state=None):\n        \"\"\"Toggle Gmail account connection on/off manually\"\"\"\n        user_entity = user_entity.upper()\n        \n        # Ensure accounts are loaded\n        if not self.all_accounts:\n            self.load_gmail_accounts()\n        \n        if account_key not in self.all_accounts:\n            logging.error(f\"Account {account_key} not found\")\n            return False\n        \n        account_info = self.all_accounts[account_key]\n        account_entity = account_info['entity']\n        \n        # Check permissions\n        if user_entity == 'TSSW':\n            # TSSW can toggle any account\n            pass\n        elif user_entity == account_entity:\n            # Users can toggle their own entity accounts (if they have permission)\n            pass\n        else:\n            logging.error(f\"User {user_id} from {user_entity} cannot toggle {account_key}\")\n            return False\n        \n        with self.lock:\n            current_state = self.get_account_connection_status(account_key)\n            \n            # Determine target state\n            if force_state:\n                target_state = force_state\n            else:\n                target_state = 'off' if current_state == 'connected' else 'on'\n            \n            # Record the toggle\n            self.manual_toggles[account_key] = {\n                'state': target_state,\n                'toggled_by': user_id,\n                'toggle_time': time.time(),\n                'user_entity': user_entity\n            }\n            \n            if target_state == 'off':\n                # Disconnect account\n                self.forced_disconnects.add(account_key)\n                if user_entity == 'TSSW':\n                    # TSSW can force disconnect\n                    self._force_disconnect_account(account_key)\n                else:\n                    # Regular users can only disconnect if no entity users are logged in\n                    if not self.logged_users.get(account_entity):\n                        self._close_connection(account_key)\n                logging.info(f\"Account {account_key} toggled OFF by {user_id} ({user_entity})\")\n            else:\n                # Connect account\n                self.forced_disconnects.discard(account_key)\n                self._force_connect_account(account_key, account_info)\n                logging.info(f\"Account {account_key} toggled ON by {user_id} ({user_entity})\")\n            \n            return True\n    \n    def get_account_connection_status(self, account_key):\n        \"\"\"Get the current connection status of an account\"\"\"\n        if account_key not in self.all_accounts:\n            return 'unknown'\n        \n        account_info = self.all_accounts[account_key]\n        entity = account_info['entity']\n        \n        # Check if manually forced off\n        if account_key in self.forced_disconnects:\n            # Check if entity has logged users (auto-reconnect condition)\n            if entity != 'TSSW' and self.logged_users.get(entity):\n                # Should be auto-reconnected\n                return 'connected'\n            else:\n                return 'disconnected'\n        \n        # Check actual connection status\n        if (entity in self.entity_connections and \n            account_key in self.entity_connections[entity] and\n            account_key in self.email_cache):\n            return 'connected'\n        else:\n            return 'disconnected'\n    \n    def get_all_accounts_status(self, user_entity):\n        \"\"\"Get connection status for all accounts accessible to user\"\"\"\n        user_entity = user_entity.upper()\n        accounts_status = {}\n        \n        # Get accessible accounts\n        accessible_accounts = self.get_user_accounts(user_entity)\n        \n        for account_key, account_info in accessible_accounts.items():\n            status = self.get_account_connection_status(account_key)\n            toggle_info = self.manual_toggles.get(account_key, {})\n            \n            accounts_status[account_key] = {\n                'status': status,\n                'entity': account_info['entity'],\n                'email': account_info['email'],\n                'display_name': account_info['display_name'],\n                'last_toggled_by': toggle_info.get('toggled_by'),\n                'last_toggle_time': toggle_info.get('toggle_time'),\n                'email_count': len(self.email_cache.get(account_key, []))\n            }\n        \n        return accounts_status\n    \n    def _force_connect_account(self, account_key, account_info):\n        \"\"\"Force connect a specific account\"\"\"\n        try:\n            # Remove from forced disconnects\n            self.forced_disconnects.discard(account_key)\n            \n            # Check if already connected\n            entity = account_info['entity']\n            if (entity in self.entity_connections and \n                account_key in self.entity_connections[entity]):\n                logging.info(f\"Account {account_key} already connected\")\n                return\n            \n            # Start connection\n            self._start_connection_safe(account_key, account_info)\n            logging.info(f\"Force connected account {account_key}\")\n            \n        except Exception as e:\n            logging.error(f\"Failed to force connect {account_key}: {e}\")\n    \n    def _force_disconnect_account(self, account_key):\n        \"\"\"Force disconnect a specific account\"\"\"\n        try:\n            # Add to forced disconnects\n            self.forced_disconnects.add(account_key)\n            \n            # Close the connection\n            self._close_connection(account_key)\n            logging.info(f\"Force disconnected account {account_key}\")\n            \n        except Exception as e:\n            logging.error(f\"Failed to force disconnect {account_key}: {e}\")\n    \n    def _start_single_connection(self, account_key, account_info):\n        \"\"\"Start connection for a single account (used by TSSW)\"\"\"\n        try:\n            # Create IMAP connection\n            mail = imaplib.IMAP4_SSL('imap.gmail.com', 993)\n            mail.login(account_info['email'], account_info['app_password'])\n            mail.select('INBOX')\n            \n            connection_info = {\n                'mail': mail,\n                'account_info': account_info,\n                'thread': None,\n                'stop_event': threading.Event(),\n                'last_update': time.time(),\n                'single_account': True  # Mark as single account connection\n            }\n            \n            # Store in entity connections\n            entity = account_info['entity']\n            if entity not in self.entity_connections:\n                self.entity_connections[entity] = {}\n            self.entity_connections[entity][account_key] = connection_info\n            \n            # Initialize connection stats\n            self._init_connection_stats(account_key)\n            \n            # Fetch initial emails\n            self._fetch_emails(account_key)\n            \n            # Start monitoring thread\n            monitor_thread = threading.Thread(\n                target=self._monitor_connection,\n                args=(account_key,),\n                daemon=True\n            )\n            monitor_thread.start()\n            connection_info['thread'] = monitor_thread\n            \n            logging.info(f\"Started single connection for {account_key}\")\n            \n        except Exception as e:\n            logging.error(f\"Failed to start single connection for {account_key}: {e}\")\n    \n    def add_update_callback(self, account_key, callback):\n        \"\"\"Add a callback function to be called when emails are updated\"\"\"\n        with self.lock:\n            self.update_callbacks[account_key].append(callback)\n    \n    def _activate_entity_fast(self, entity):\n        \"\"\"Fast activate entity - likely already pre-connected\"\"\"\n        if entity in self.active_entities:\n            return  # Already active\n        \n        self.active_entities.add(entity)\n        \n        # Check if already pre-connected\n        if entity in self.pre_connected_entities:\n            logging.info(f\"Entity {entity} was pre-connected, activation instant!\")\n            return\n        \n        # If not pre-connected, activate with error handling\n        self._activate_entity_with_fallback(entity)\n    \n    def _activate_entity_with_fallback(self, entity):\n        \"\"\"Activate entity with sequential connection and prioritization\"\"\"\n        try:\n            # Ensure accounts are loaded\n            if not self.all_accounts:\n                self.load_gmail_accounts()\n            \n            # Connect all accounts for this entity\n            entity_accounts = {k: v for k, v in self.all_accounts.items() if v['entity'] == entity}\n            \n            if entity not in self.entity_connections:\n                self.entity_connections[entity] = {}\n            \n            # NEW: Sequential connection with prioritization and delays\n            prioritized_accounts = self._prioritize_accounts_for_entity(entity, entity_accounts)\n            \n            successful_connections = 0\n            for account_key, account_info in prioritized_accounts:\n                try:\n                    logging.info(f\"Rebuild Connection with {account_info['email']}...\")\n                    self._start_connection_safe(account_key, account_info)\n                    successful_connections += 1\n                    \n                    # Add 200ms delay between connection attempts\n                    time.sleep(0.2)\n                    \n                except Exception as e:\n                    logging.error(f\"Failed to connect {account_key}: {e}\")\n                    # Continue with other accounts instead of failing completely\n                    continue\n            \n            logging.info(f\"Activated entity {entity} with {successful_connections}/{len(entity_accounts)} accounts connected\")\n            \n        except Exception as e:\n            logging.error(f\"Error activating entity {entity}: {e}\")\n            # Fallback: try to activate accounts one by one with even more error handling\n            self._activate_entity_fallback_mode(entity)\n    \n    def _activate_entity_fallback_mode(self, entity):\n        \"\"\"Fallback activation mode - connect accounts one by one with retries and delays\"\"\"\n        logging.info(f\"Using fallback mode for entity {entity}\")\n        \n        try:\n            entity_accounts = {k: v for k, v in self.all_accounts.items() if v['entity'] == entity}\n            prioritized_accounts = self._prioritize_accounts_for_entity(entity, entity_accounts)\n            \n            for account_key, account_info in prioritized_accounts:\n                try:\n                    logging.info(f\"Rebuild Connection with {account_info['email']} (fallback mode)...\")\n                    self._start_connection_with_retry(account_key, account_info)\n                    \n                    # Add 200ms delay between connection attempts\n                    time.sleep(0.2)\n                    \n                except Exception as e:\n                    logging.error(f\"Failed to connect {account_key} even in fallback mode: {e}\")\n                    # Continue with other accounts\n                    continue\n        except Exception as e:\n            logging.error(f\"Critical error in fallback mode for {entity}: {e}\")\n    \n    def _prioritize_accounts_for_entity(self, entity, entity_accounts):\n        \"\"\"Prioritize accounts based on active user usage\"\"\"\n        priority_accounts = []\n        regular_accounts = []\n        \n        # Get accounts currently being used by active users\n        with self.lock:\n            active_account_keys = set()\n            \n            # Add accounts selected by TSSW users\n            for user_id, account_key in self.tssw_selected_accounts.items():\n                if account_key in entity_accounts:\n                    active_account_keys.add(account_key)\n            \n            # Add accounts from entities with active users\n            for active_entity, users in self.logged_users.items():\n                if users and active_entity == entity:  # This entity has active users\n                    for account_key in entity_accounts:\n                        if account_key.startswith(f\"{active_entity}_\"):\n                            active_account_keys.add(account_key)\n        \n        # Separate into priority (active) and regular accounts\n        for account_key, account_info in entity_accounts.items():\n            if account_key in active_account_keys:\n                priority_accounts.append((account_key, account_info))\n            else:\n                regular_accounts.append((account_key, account_info))\n        \n        # Return prioritized list: active accounts first, then regular accounts\n        return priority_accounts + regular_accounts\n    \n    def _activate_entity(self, entity):\n        \"\"\"Legacy activate method - now redirects to fast activation\"\"\"\n        self._activate_entity_fast(entity)\n    \n    def _deactivate_entity(self, entity):\n        \"\"\"Deactivate all Gmail connections for an entity\"\"\"\n        if entity not in self.active_entities:\n            return  # Already inactive\n        \n        self.active_entities.discard(entity)\n        \n        # Close all connections for this entity\n        if entity in self.entity_connections:\n            for account_key in list(self.entity_connections[entity].keys()):\n                self._close_connection(account_key)\n            del self.entity_connections[entity]\n        \n        logging.info(f\"Deactivated entity {entity}\")\n    \n    def _check_tssw_deactivation(self):\n        \"\"\"Check if we should deactivate entities after TSSW logout\"\"\"\n        # Keep entities active if they have their own users logged in\n        entities_to_keep = set(entity for entity, users in self.logged_users.items() if users and entity != 'TSSW')\n        \n        # Deactivate entities that don't have their own users\n        entities_to_deactivate = self.active_entities - entities_to_keep - {'TSSW'}\n        for entity in entities_to_deactivate:\n            self._deactivate_entity(entity)\n    \n    def _start_connection_safe(self, account_key, account_info):\n        \"\"\"Thread-safe connection starter with comprehensive error handling\"\"\"\n        try:\n            self._start_connection_with_retry(account_key, account_info)\n        except Exception as e:\n            logging.error(f\"Critical error in safe connection for {account_key}: {e}\")\n            # Even if this account fails, don't crash the whole system\n    \n    def _start_connection_with_retry(self, account_key, account_info):\n        \"\"\"Start connection with retry logic and fallback mechanisms\"\"\"\n        max_attempts = self.max_retries\n        \n        for attempt in range(max_attempts):\n            try:\n                # Check if we've exceeded retry limit for this account\n                if self.connection_retry_counts[account_key] >= max_attempts:\n                    logging.warning(f\"Account {account_key} exceeded retry limit, adding to problem accounts\")\n                    return\n                \n                # Attempt connection\n                self._start_connection_core(account_key, account_info)\n                \n                # Reset retry count on success\n                self.connection_retry_counts[account_key] = 0\n                return\n                \n            except Exception as e:\n                self.connection_retry_counts[account_key] += 1\n                logging.warning(f\"Connection attempt {attempt + 1} failed for {account_key}: {e}\")\n                \n                if attempt < max_attempts - 1:\n                    # Wait before retry (exponential backoff)\n                    wait_time = (2 ** attempt) * 1\n                    time.sleep(wait_time)\n                else:\n                    logging.error(f\"All connection attempts failed for {account_key}\")\n                    # Try backup connection method\n                    self._try_backup_connection(account_key, account_info)\n    \n    def _start_connection_core(self, account_key, account_info):\n        \"\"\"Core connection logic with enhanced error handling\"\"\"\n        try:\n            # Create IMAP connection with timeout\n            mail = imaplib.IMAP4_SSL('imap.gmail.com', 993)\n            mail.sock.settimeout(30)  # 30 second timeout\n            \n            # Login with error handling\n            try:\n                mail.login(account_info['email'], account_info['app_password'])\n            except imaplib.IMAP4.error as e:\n                if 'authentication failed' in str(e).lower():\n                    logging.error(f\"Authentication failed for {account_key}: Check app password\")\n                    raise Exception(f\"Authentication failed: {e}\")\n                else:\n                    raise\n            \n            # Select inbox with fallback\n            try:\n                mail.select('INBOX')\n            except Exception as e:\n                logging.warning(f\"Could not select INBOX for {account_key}, trying alternative\")\n                mail.select()  # Select default folder\n            \n            connection_info = {\n                'mail': mail,\n                'account_info': account_info,\n                'thread': None,\n                'stop_event': threading.Event(),\n                'last_update': time.time(),\n                'connection_type': 'primary',\n                'created_at': time.time()\n            }\n            \n            # Store in entity connections\n            entity = account_info['entity']\n            with self.lock:\n                if entity not in self.entity_connections:\n                    self.entity_connections[entity] = {}\n                self.entity_connections[entity][account_key] = connection_info\n            \n            # Initialize connection stats\n            self._init_connection_stats(account_key)\n            \n            # Fetch initial emails with error handling\n            try:\n                self._fetch_emails(account_key)\n            except Exception as e:\n                logging.warning(f\"Initial email fetch failed for {account_key}: {e}\")\n                # Continue anyway, emails will be fetched later\n            \n            # Start monitoring thread\n            monitor_thread = threading.Thread(\n                target=self._monitor_connection_safe,\n                args=(account_key,),\n                daemon=True\n            )\n            monitor_thread.start()\n            connection_info['thread'] = monitor_thread\n            \n            logging.info(f\"Successfully started connection for {account_key}\")\n            \n        except Exception as e:\n            logging.error(f\"Core connection failed for {account_key}: {e}\")\n            raise\n    \n    def _try_backup_connection(self, account_key, account_info):\n        \"\"\"Try alternative connection method as backup\"\"\"\n        try:\n            logging.info(f\"Trying backup connection method for {account_key}\")\n            \n            # Store backup connection info (simplified)\n            backup_info = {\n                'account_info': account_info,\n                'status': 'backup_needed',\n                'last_attempt': time.time(),\n                'retry_after': time.time() + 300  # Retry after 5 minutes\n            }\n            \n            self.backup_connections[account_key] = backup_info\n            logging.info(f\"Scheduled backup retry for {account_key}\")\n            \n        except Exception as e:\n            logging.error(f\"Backup connection setup failed for {account_key}: {e}\")\n    \n    def _monitor_connection_safe(self, account_key):\n        \"\"\"Enhanced monitoring with comprehensive error handling\"\"\"\n        entity = account_key.split('_')[0]\n        consecutive_errors = 0\n        max_consecutive_errors = 5\n        \n        while (entity in self.entity_connections and \n               account_key in self.entity_connections[entity]):\n            \n            connection_info = self.entity_connections[entity][account_key]\n            \n            if connection_info['stop_event'].is_set():\n                break\n            \n            try:\n                # Poll every 5 seconds for new emails\n                time.sleep(5)\n                \n                if connection_info['stop_event'].is_set():\n                    break\n                \n                # Fetch emails with error handling\n                try:\n                    self._fetch_emails(account_key)\n                    consecutive_errors = 0  # Reset on success\n                except Exception as e:\n                    consecutive_errors += 1\n                    logging.warning(f\"Email fetch error for {account_key}: {e}\")\n                    \n                    if consecutive_errors >= max_consecutive_errors:\n                        logging.error(f\"Too many consecutive errors for {account_key}, triggering rebuild\")\n                        self._smart_rebuild_connection(account_key)\n                        consecutive_errors = 0\n                \n            except Exception as e:\n                consecutive_errors += 1\n                logging.error(f\"Monitor error for {account_key}: {e}\")\n                \n                if consecutive_errors >= max_consecutive_errors:\n                    logging.error(f\"Monitor failure for {account_key}, attempting recovery\")\n                    try:\n                        self._emergency_connection_recovery(account_key)\n                    except Exception as recovery_error:\n                        logging.error(f\"Emergency recovery failed for {account_key}: {recovery_error}\")\n                    consecutive_errors = 0\n                \n                time.sleep(30)  # Wait longer after errors\n    \n    def _emergency_connection_recovery(self, account_key):\n        \"\"\"Last resort connection recovery\"\"\"\n        logging.info(f\"Starting emergency recovery for {account_key}\")\n        \n        entity = account_key.split('_')[0]\n        \n        # Force close existing connection\n        with self.lock:\n            if (entity in self.entity_connections and \n                account_key in self.entity_connections[entity]):\n                \n                connection_info = self.entity_connections[entity][account_key]\n                connection_info['stop_event'].set()\n                \n                try:\n                    connection_info['mail'].close()\n                    connection_info['mail'].logout()\n                except:\n                    pass\n        \n        # Wait a moment\n        time.sleep(5)\n        \n        # Attempt to recreate connection\n        if account_key in self.all_accounts:\n            account_info = self.all_accounts[account_key]\n            self._start_connection_with_retry(account_key, account_info)\n    \n    def _start_auto_reconnect_checker(self):\n        \"\"\"Start background thread to check for auto-reconnect conditions\"\"\"\n        def auto_reconnect_loop():\n            while not self.health_monitor_stop.is_set():\n                try:\n                    self._check_auto_reconnect()\n                    time.sleep(30)  # Check every 30 seconds\n                except Exception as e:\n                    logging.error(f\"Error in auto-reconnect loop: {e}\")\n                    time.sleep(60)  # Wait longer on error\n        \n        reconnect_thread = threading.Thread(target=auto_reconnect_loop, daemon=True)\n        reconnect_thread.start()\n        logging.info(\"Auto-reconnect checker started\")\n    \n    def _check_auto_reconnect(self):\n        \"\"\"Check for accounts that should be auto-reconnected due to entity users being logged in\"\"\"\n        try:\n            for account_key in list(self.forced_disconnects):\n                if account_key not in self.all_accounts:\n                    continue\n                    \n                account_info = self.all_accounts[account_key]\n                entity = account_info['entity']\n                \n                # If entity has logged users, auto-reconnect\n                if entity != 'TSSW' and self.logged_users.get(entity):\n                    logging.info(f\"Auto-reconnecting {account_key} due to {entity} users logged in\")\n                    self._force_connect_account(account_key, account_info)\n                    # Keep in forced_disconnects but connected (for UI state)\n            \n        except Exception as e:\n            logging.error(f\"Error in auto-reconnect check: {e}\")\n    \n    def _start_connection(self, account_key, account_info):\n        \"\"\"Legacy method - now redirects to safe connection\"\"\"\n        self._start_connection_safe(account_key, account_info)\n    \n    def _load_usage_history(self):\n        \"\"\"Load usage history from persistent storage\"\"\"\n        try:\n            if os.path.exists(self.usage_history_file):\n                with open(self.usage_history_file, 'r') as f:\n                    data = json.load(f)\n                    self.usage_analytics = data.get('usage_analytics', {})\n                    self.warm_pool = set(data.get('warm_pool', []))\n                    logging.info(f\"Loaded usage history: {len(self.usage_analytics)} entities tracked\")\n            else:\n                logging.info(\"No usage history found, starting fresh\")\n        except Exception as e:\n            logging.error(f\"Error loading usage history: {e}\")\n            # Continue with empty analytics\n    \n    def _save_usage_history(self):\n        \"\"\"Save usage history to persistent storage\"\"\"\n        try:\n            data = {\n                'usage_analytics': self.usage_analytics,\n                'warm_pool': list(self.warm_pool),\n                'last_updated': time.time()\n            }\n            with open(self.usage_history_file, 'w') as f:\n                json.dump(data, f, indent=2)\n        except Exception as e:\n            logging.error(f\"Error saving usage history: {e}\")\n    \n    def _initialize_intelligent_preconnections(self):\n        \"\"\"Initialize intelligent pre-connections based on usage patterns\"\"\"\n        try:\n            current_time = time.time()\n            current_hour = datetime.now().hour\n            \n            # Pre-connect entities that were active in last 24 hours\n            entities_to_preconnect = set()\n            \n            for entity, analytics in self.usage_analytics.items():\n                # Check recent activity (last 24 hours)\n                recent_logins = [\n                    login_time for login_time in analytics.get('login_times', [])\n                    if current_time - login_time < 86400  # 24 hours\n                ]\n                \n                if recent_logins:\n                    entities_to_preconnect.add(entity)\n                \n                # Check if this hour is typically active for this entity\n                typical_hours = analytics.get('typical_hours', [])\n                if current_hour in typical_hours:\n                    entities_to_preconnect.add(entity)\n            \n            # Pre-connect identified entities in background\n            if entities_to_preconnect:\n                preconnect_thread = threading.Thread(\n                    target=self._preconnect_entities_background,\n                    args=(entities_to_preconnect,),\n                    daemon=True\n                )\n                preconnect_thread.start()\n            \n            # Maintain warm pool (top 5 most used accounts)\n            self._maintain_warm_pool()\n            \n            logging.info(f\"Intelligent pre-connections initialized: {len(entities_to_preconnect)} entities scheduled\")\n            \n        except Exception as e:\n            logging.error(f\"Error in intelligent pre-connections: {e}\")\n            # Continue without pre-connections\n    \n    def _preconnect_entities_background(self, entities_to_preconnect):\n        \"\"\"Pre-connect entities in background thread\"\"\"\n        for entity in entities_to_preconnect:\n            try:\n                self._preconnect_entity_safe(entity)\n                time.sleep(2)  # Small delay between connections\n            except Exception as e:\n                logging.error(f\"Background pre-connection failed for {entity}: {e}\")\n    \n    def _preconnect_entity_safe(self, entity):\n        \"\"\"Safely pre-connect an entity with error handling\"\"\"\n        try:\n            if entity not in self.pre_connected_entities:\n                logging.info(f\"Pre-connecting entity {entity}\")\n                \n                # Load accounts if not loaded\n                if not self.all_accounts:\n                    self.load_gmail_accounts()\n                \n                # Pre-connect accounts for this entity\n                entity_accounts = {k: v for k, v in self.all_accounts.items() if v['entity'] == entity}\n                \n                if entity not in self.entity_connections:\n                    self.entity_connections[entity] = {}\n                \n                # Connect accounts with error handling\n                for account_key, account_info in entity_accounts.items():\n                    try:\n                        self._start_connection_safe(account_key, account_info)\n                    except Exception as e:\n                        logging.warning(f\"Pre-connection failed for {account_key}: {e}\")\n                        # Continue with other accounts\n                \n                self.pre_connected_entities.add(entity)\n                logging.info(f\"Successfully pre-connected entity {entity}\")\n                \n        except Exception as e:\n            logging.error(f\"Error pre-connecting entity {entity}: {e}\")\n    \n    def _maintain_warm_pool(self):\n        \"\"\"Maintain warm pool of most-used accounts\"\"\"\n        try:\n            # Calculate account usage scores\n            account_scores = {}\n            \n            for entity, analytics in self.usage_analytics.items():\n                login_count = analytics.get('login_count', 0)\n                recent_activity = len([\n                    t for t in analytics.get('login_times', [])\n                    if time.time() - t < 604800  # Last week\n                ])\n                \n                # Score based on total logins and recent activity\n                score = login_count + (recent_activity * 2)\n                \n                # Add all accounts for this entity to scoring\n                if self.all_accounts:\n                    entity_accounts = {k: v for k, v in self.all_accounts.items() if v['entity'] == entity}\n                    for account_key in entity_accounts:\n                        account_scores[account_key] = score\n            \n            # Select top accounts for warm pool\n            if account_scores:\n                top_accounts = sorted(account_scores.items(), key=lambda x: x[1], reverse=True)\n                new_warm_pool = set([account for account, score in top_accounts[:self.max_warm_pool_size]])\n                \n                # Update warm pool connections\n                self._update_warm_pool(new_warm_pool)\n            \n        except Exception as e:\n            logging.error(f\"Error maintaining warm pool: {e}\")\n    \n    def _update_warm_pool(self, new_warm_pool):\n        \"\"\"Update warm pool connections\"\"\"\n        try:\n            old_warm_pool = self.warm_pool.copy()\n            self.warm_pool = new_warm_pool\n            \n            # Connect new accounts in background\n            for account_key in new_warm_pool - old_warm_pool:\n                if self.all_accounts and account_key in self.all_accounts:\n                    try:\n                        account_info = self.all_accounts[account_key]\n                        self._start_connection_safe(account_key, account_info)\n                        logging.info(f\"Added {account_key} to warm pool\")\n                    except Exception as e:\n                        logging.warning(f\"Failed to add {account_key} to warm pool: {e}\")\n            \n        except Exception as e:\n            logging.error(f\"Error updating warm pool: {e}\")\n    \n    def _record_login_analytics(self, user_entity):\n        \"\"\"Record login analytics for intelligence\"\"\"\n        try:\n            if user_entity not in self.usage_analytics:\n                self.usage_analytics[user_entity] = {\n                    'login_count': 0,\n                    'login_times': [],\n                    'typical_hours': [],\n                    'first_seen': time.time()\n                }\n            \n            analytics = self.usage_analytics[user_entity]\n            current_time = time.time()\n            current_hour = datetime.now().hour\n            \n            # Update login count\n            analytics['login_count'] += 1\n            \n            # Add login time (keep last 100 logins)\n            analytics['login_times'].append(current_time)\n            if len(analytics['login_times']) > 100:\n                analytics['login_times'] = analytics['login_times'][-100:]\n            \n            # Update typical hours\n            hour_counter = Counter(analytics.get('typical_hours', []))\n            hour_counter[current_hour] += 1\n            \n            # Keep top 6 most common hours\n            analytics['typical_hours'] = [hour for hour, count in hour_counter.most_common(6)]\n            \n            # Save analytics periodically\n            if analytics['login_count'] % 10 == 0:  # Save every 10 logins\n                self._save_usage_history()\n            \n        except Exception as e:\n            logging.error(f\"Error recording login analytics: {e}\")\n    \n    def _prewarm_tssw_connections(self, user_id):\n        \"\"\"Pre-warm connections for TSSW users based on their usage patterns\"\"\"\n        try:\n            # Get TSSW user's most common account selections from analytics\n            # For now, pre-warm the warm pool accounts\n            for account_key in list(self.warm_pool)[:3]:  # Top 3 accounts\n                if self.all_accounts and account_key in self.all_accounts:\n                    try:\n                        account_info = self.all_accounts[account_key]\n                        self._start_connection_safe(account_key, account_info)\n                    except Exception as e:\n                        logging.warning(f\"TSSW pre-warm failed for {account_key}: {e}\")\n            \n        except Exception as e:\n            logging.error(f\"Error pre-warming TSSW connections: {e}\")\n    \n    def _update_usage_analytics(self, account_key):\n        \"\"\"Update usage analytics when account is accessed\"\"\"\n        try:\n            entity = account_key.split('_')[0]\n            if entity in self.usage_analytics:\n                analytics = self.usage_analytics[entity]\n                analytics['last_accessed'] = time.time()\n                \n                # Track account-specific usage\n                if 'account_usage' not in analytics:\n                    analytics['account_usage'] = {}\n                \n                if account_key not in analytics['account_usage']:\n                    analytics['account_usage'][account_key] = 0\n                \n                analytics['account_usage'][account_key] += 1\n                \n        except Exception as e:\n            logging.error(f\"Error updating usage analytics: {e}\")\n    \n    def _close_connection(self, account_key):\n        \"\"\"Close an IMAP connection\"\"\"\n        entity = account_key.split('_')[0]\n        \n        if entity in self.entity_connections and account_key in self.entity_connections[entity]:\n            connection_info = self.entity_connections[entity][account_key]\n            \n            # Signal thread to stop\n            connection_info['stop_event'].set()\n            \n            # Close IMAP connection\n            try:\n                connection_info['mail'].close()\n                connection_info['mail'].logout()\n            except:\n                pass\n            \n            # Clean up\n            del self.entity_connections[entity][account_key]\n            if account_key in self.email_cache:\n                del self.email_cache[account_key]\n            if account_key in self.update_callbacks:\n                del self.update_callbacks[account_key]\n            if account_key in self.connection_stats:\n                del self.connection_stats[account_key]\n            \n            logging.info(f\"Closed connection for {account_key}\")\n    \n    def _monitor_connection(self, account_key):\n        \"\"\"Monitor IMAP connection using polling\"\"\"\n        entity = account_key.split('_')[0]\n        \n        while (entity in self.entity_connections and \n               account_key in self.entity_connections[entity]):\n            \n            connection_info = self.entity_connections[entity][account_key]\n            \n            if connection_info['stop_event'].is_set():\n                break\n            \n            try:\n                # Poll every 5 seconds for new emails (enhanced speed)\n                time.sleep(5)\n                \n                if connection_info['stop_event'].is_set():\n                    break\n                \n                # Fetch emails periodically\n                self._fetch_emails(account_key)\n                \n            except Exception as e:\n                logging.error(f\"Monitor error for {account_key}: {e}\")\n                # Try to reconnect\n                self._reconnect(account_key)\n                time.sleep(30)\n    \n    def _reconnect(self, account_key):\n        \"\"\"Reconnect to Gmail account\"\"\"\n        entity = account_key.split('_')[0]\n        \n        if (entity not in self.entity_connections or \n            account_key not in self.entity_connections[entity]):\n            return\n        \n        connection_info = self.entity_connections[entity][account_key]\n        account_info = connection_info['account_info']\n        \n        try:\n            # Close old connection\n            try:\n                connection_info['mail'].close()\n                connection_info['mail'].logout()\n            except:\n                pass\n            \n            # Create new connection\n            mail = imaplib.IMAP4_SSL('imap.gmail.com', 993)\n            mail.login(account_info['email'], account_info['app_password'])\n            mail.select('INBOX')\n            \n            connection_info['mail'] = mail\n            logging.info(f\"Reconnected to {account_key}\")\n            \n            # Fetch latest emails\n            self._fetch_emails(account_key)\n            \n        except Exception as e:\n            logging.error(f\"Failed to reconnect to {account_key}: {e}\")\n    \n    def _start_health_monitoring(self):\n        \"\"\"Start global health monitoring thread\"\"\"\n        if self.health_monitor_thread is None or not self.health_monitor_thread.is_alive():\n            self.health_monitor_thread = threading.Thread(\n                target=self._health_monitor_loop,\n                daemon=True\n            )\n            self.health_monitor_thread.start()\n            logging.info(\"Started global health monitoring thread\")\n    \n    def _health_monitor_loop(self):\n        \"\"\"Global health monitoring loop - checks all connections every 5 minutes\"\"\"\n        while not self.health_monitor_stop.is_set():\n            try:\n                # Wait for health check interval (5 minutes)\n                if self.health_monitor_stop.wait(self.health_check_interval):\n                    break\n                \n                # Check health of all active connections\n                self._check_all_connections_health()\n                \n            except Exception as e:\n                logging.error(f\"Error in health monitor loop: {e}\")\n                time.sleep(30)  # Wait before retrying\n    \n    def _check_all_connections_health(self):\n        \"\"\"Check health of all active connections and rebuild if needed\"\"\"\n        with self.lock:\n            all_accounts_to_check = []\n            \n            # Collect all active account keys\n            for entity_connections in self.entity_connections.values():\n                for account_key in entity_connections.keys():\n                    if account_key not in self.rebuilding_connections:\n                        all_accounts_to_check.append(account_key)\n        \n        # Check each connection (outside of lock to avoid blocking)\n        # Sequential processing with delays to prevent overwhelming Gmail servers\n        for account_key in all_accounts_to_check:\n            try:\n                if self._needs_rebuild(account_key):\n                    self._smart_rebuild_connection(account_key)\n                    # Add 200ms delay after rebuild to prevent overwhelming Gmail\n                    time.sleep(0.2)\n                else:\n                    # Send heartbeat to keep connection alive\n                    self._send_heartbeat(account_key)\n            except Exception as e:\n                logging.error(f\"Error checking health for {account_key}: {e}\")\n                # Small delay even on error to prevent rapid retries\n                time.sleep(0.1)\n    \n    def _needs_rebuild(self, account_key):\n        \"\"\"Check if connection needs rebuilding (unhealthy or too old)\"\"\"\n        stats = self.connection_stats.get(account_key)\n        if not stats:\n            return True  # No stats means we should rebuild\n        \n        current_time = time.time()\n        \n        # Check if connection is too old (>15 minutes)\n        if current_time - stats['created_time'] > self.max_connection_age:\n            logging.debug(f\"Connection {account_key} is too old, needs rebuild\")\n            return True\n        \n        # Check if connection is unhealthy (too many recent errors)\n        if stats['error_count'] > 3:\n            logging.debug(f\"Connection {account_key} has too many errors, needs rebuild\")\n            return True\n        \n        # Check if last heartbeat failed\n        if stats.get('last_heartbeat_failed', False):\n            logging.debug(f\"Connection {account_key} heartbeat failed, needs rebuild\")\n            return True\n        \n        return False\n    \n    def _send_heartbeat(self, account_key):\n        \"\"\"Send IMAP NOOP command to keep connection alive\"\"\"\n        entity = account_key.split('_')[0]\n        \n        with self.lock:\n            if (entity not in self.entity_connections or \n                account_key not in self.entity_connections[entity]):\n                return\n            \n            connection_info = self.entity_connections[entity][account_key]\n            mail = connection_info['mail']\n        \n        try:\n            # Send NOOP command to keep connection alive\n            status, response = mail.noop()\n            if status == 'OK':\n                self._update_connection_stats(account_key, 'heartbeat_success')\n                logging.debug(f\"Heartbeat successful for {account_key}\")\n            else:\n                self._update_connection_stats(account_key, 'heartbeat_failed')\n                logging.warning(f\"Heartbeat failed for {account_key}: {response}\")\n        except Exception as e:\n            self._update_connection_stats(account_key, 'heartbeat_error')\n            logging.warning(f\"Heartbeat error for {account_key}: {e}\")\n    \n    def _smart_rebuild_connection(self, account_key):\n        \"\"\"Intelligently rebuild a connection with rolling reconnection\"\"\"\n        entity = account_key.split('_')[0]\n        \n        # Mark as rebuilding to prevent concurrent rebuilds\n        with self.lock:\n            if account_key in self.rebuilding_connections:\n                return  # Already being rebuilt\n            self.rebuilding_connections.add(account_key)\n        \n        try:\n            # Get account info\n            with self.lock:\n                if (entity not in self.entity_connections or \n                    account_key not in self.entity_connections[entity]):\n                    return\n                \n                connection_info = self.entity_connections[entity][account_key]\n                account_info = connection_info['account_info']\n            \n            logging.info(f\"Rebuild Connection with {account_info['email']}...\")\n            \n            # Create new connection\n            new_mail = imaplib.IMAP4_SSL('imap.gmail.com', 993)\n            new_mail.login(account_info['email'], account_info['app_password'])\n            new_mail.select('INBOX')\n            \n            # Replace old connection atomically\n            with self.lock:\n                if (entity in self.entity_connections and \n                    account_key in self.entity_connections[entity]):\n                    \n                    old_connection_info = self.entity_connections[entity][account_key]\n                    \n                    # Close old connection\n                    try:\n                        old_connection_info['mail'].close()\n                        old_connection_info['mail'].logout()\n                    except:\n                        pass\n                    \n                    # Update with new connection\n                    old_connection_info['mail'] = new_mail\n                    \n                    # Reset connection stats\n                    self._init_connection_stats(account_key)\n                    \n                    logging.info(f\"Successfully rebuilt connection for {account_key}\")\n            \n            # Fetch latest emails with new connection\n            self._fetch_emails(account_key)\n            \n        except Exception as e:\n            logging.error(f\"Failed to smart rebuild connection for {account_key}: {e}\")\n            # If rebuild fails, try standard reconnection\n            self._reconnect(account_key)\n        \n        finally:\n            # Remove from rebuilding set\n            with self.lock:\n                self.rebuilding_connections.discard(account_key)\n    \n    def _init_connection_stats(self, account_key):\n        \"\"\"Initialize connection statistics\"\"\"\n        self.connection_stats[account_key] = {\n            'created_time': time.time(),\n            'last_heartbeat': time.time(),\n            'last_heartbeat_failed': False,\n            'error_count': 0,\n            'email_fetch_count': 0,\n            'last_email_fetch': None,\n            'health_status': 'healthy'\n        }\n    \n    def _update_connection_stats(self, account_key, event_type, error=None):\n        \"\"\"Update connection statistics\"\"\"\n        if account_key not in self.connection_stats:\n            self._init_connection_stats(account_key)\n        \n        stats = self.connection_stats[account_key]\n        current_time = time.time()\n        \n        if event_type == 'heartbeat_success':\n            stats['last_heartbeat'] = current_time\n            stats['last_heartbeat_failed'] = False\n            stats['health_status'] = 'healthy'\n        elif event_type == 'heartbeat_failed':\n            stats['last_heartbeat_failed'] = True\n            stats['error_count'] += 1\n            stats['health_status'] = 'unhealthy'\n        elif event_type == 'heartbeat_error':\n            stats['last_heartbeat_failed'] = True\n            stats['error_count'] += 1\n            stats['health_status'] = 'error'\n        elif event_type == 'email_fetch_success':\n            stats['email_fetch_count'] += 1\n            stats['last_email_fetch'] = current_time\n            # Reset error count on successful operation\n            stats['error_count'] = max(0, stats['error_count'] - 1)\n        elif event_type == 'email_fetch_error':\n            stats['error_count'] += 1\n        elif event_type == 'connection_reset':\n            # Reset stats after successful rebuild\n            stats['created_time'] = current_time\n            stats['error_count'] = 0\n            stats['last_heartbeat'] = current_time\n            stats['last_heartbeat_failed'] = False\n            stats['health_status'] = 'healthy'\n\n    def _fetch_emails(self, account_key):\n        \"\"\"Fetch the last 50 emails from all folders with enhanced error handling\"\"\"\n        entity = account_key.split('_')[0]\n        \n        if (entity not in self.entity_connections or \n            account_key not in self.entity_connections[entity]):\n            logging.warning(f\"No connection found for {account_key}\")\n            return\n        \n        connection_info = self.entity_connections[entity][account_key]\n        mail = connection_info['mail']\n        \n        try:\n            # Validate connection first\n            try:\n                mail.noop()  # Test connection\n            except Exception as e:\n                logging.error(f\"Connection validation failed for {account_key}: {e}\")\n                # Try to rebuild connection\n                self._smart_rebuild_connection(account_key)\n                return\n            \n            all_emails = []\n            \n            # Get emails from key folders\n            folders_to_check = [\n                ('INBOX', 'Inbox'),\n                ('[Gmail]/Spam', 'Spam')\n            ]\n            \n            # Pre-cache Gmail categories for inbox emails\n            category_uid_cache = {}\n            \n            for folder_path, folder_name in folders_to_check:\n                try:\n                    result = mail.select(folder_path)\n                    if result[0] != 'OK':\n                        logging.warning(f\"Failed to select folder {folder_path} for {account_key}: {result}\")\n                        continue\n                    \n                    # Cache Gmail categories only for Inbox folder\n                    if folder_name == 'Inbox':\n                        categories = ['social', 'promotions', 'updates', 'forums']\n                        for cat_key in categories:\n                            try:\n                                result, data = mail.uid('SEARCH', 'X-GM-RAW', f'\"category:{cat_key}\"')\n                                category_uid_cache[cat_key] = set(data[0].split()) if result == 'OK' and data[0] else set()\n                            except Exception as e:\n                                logging.debug(f\"Error caching category {cat_key}: {e}\")\n                                category_uid_cache[cat_key] = set()\n                    \n                    # Search for all emails with better error handling\n                    result, data = mail.uid('SEARCH', None, 'ALL')\n                    if result != 'OK':\n                        logging.warning(f\"UID SEARCH failed for {folder_path} in {account_key}: {result}\")\n                        continue\n                    \n                    if not data or not data[0]:\n                        logging.info(f\"No emails found in {folder_path} for {account_key}\")\n                        continue\n                    \n                    email_uids = data[0].split()\n                    if not email_uids:\n                        logging.info(f\"Empty UID list for {folder_path} in {account_key}\")\n                        continue\n                    \n                    # Get the most recent emails from this folder\n                    recent_uids = email_uids[-30:]  # Get 30 from each folder\n                    logging.debug(f\"Processing {len(recent_uids)} emails from {folder_path} for {account_key}\")\n                    \n                    for uid in reversed(recent_uids):\n                        try:\n                            # Fetch email headers with timeout\n                            result, msg_data = mail.uid('fetch', uid, '(BODY.PEEK[HEADER.FIELDS (FROM SUBJECT DATE)] FLAGS)')\n                            if result != 'OK':\n                                logging.debug(f\"Failed to fetch UID {uid} from {account_key}: {result}\")\n                                continue\n                            \n                            if not msg_data or not msg_data[0]:\n                                logging.debug(f\"No message data for UID {uid} from {account_key}\")\n                                continue\n                            \n                            msg = email.message_from_bytes(msg_data[0][1])\n                            \n                            # Parse email data\n                            from_header = msg.get('From', '')\n                            from_name, from_email = email.utils.parseaddr(from_header)\n                            from_name = self._decode_mime_words(from_name) if from_name else from_email\n                            \n                            subject = self._decode_mime_words(msg.get('Subject', 'No Subject'))\n                            \n                            date_header = msg.get('Date', '')\n                            try:\n                                date_obj = email.utils.parsedate_to_datetime(date_header)\n                                date_timestamp = date_obj.timestamp()\n                                date_formatted = self._format_time_ago(date_obj)\n                            except:\n                                date_timestamp = datetime.now().timestamp()\n                                date_formatted = 'Unknown'\n                            \n                            # Determine folder type for inbox categorization\n                            detected_folder = self._get_gmail_folder_type_cached(uid, folder_name, category_uid_cache)\n                            \n                            email_data = {\n                                'uid': uid.decode() if isinstance(uid, bytes) else uid,\n                                'folder': detected_folder,\n                                'from_name': from_name,\n                                'from_email': from_email,\n                                'subject': subject,\n                                'date': date_formatted,\n                                'date_timestamp': date_timestamp,\n                                'folder_name': folder_name\n                            }\n                            \n                            all_emails.append(email_data)\n                            \n                        except Exception as e:\n                            logging.debug(f\"Error processing email UID {uid}: {e}\")\n                            continue\n                \n                except Exception as e:\n                    logging.error(f\"Error processing folder {folder_path} for {account_key}: {e}\")\n                    continue\n            \n            # Sort by date and keep only the 50 most recent\n            all_emails.sort(key=lambda x: x['date_timestamp'], reverse=True)\n            recent_emails = all_emails[:50]\n            \n            # Update cache\n            with self.lock:\n                self.email_cache[account_key] = recent_emails\n                connection_info['last_update'] = time.time()\n            \n            # Update connection stats for successful fetch\n            self._update_connection_stats(account_key, 'email_fetch_success')\n            \n            # Update usage analytics\n            self._update_usage_analytics(account_key)\n            \n            # Call update callbacks\n            for callback in self.update_callbacks[account_key]:\n                try:\n                    callback(account_key, recent_emails)\n                except Exception as e:\n                    logging.error(f\"Error in update callback: {e}\")\n            \n            # Log the result with appropriate level\n            if len(recent_emails) == 0:\n                logging.warning(f\"No emails fetched for {account_key} - possible connection or access issue\")\n            else:\n                logging.info(f\"Successfully fetched {len(recent_emails)} emails for {account_key}\")\n            \n        except Exception as e:\n            logging.error(f\"Critical error fetching emails for {account_key}: {e}\")\n            # Update stats for failed fetch\n            self._update_connection_stats(account_key, 'email_fetch_error', error=str(e))\n            # Try to recover connection on critical error\n            self._smart_rebuild_connection(account_key)\n    \n    def _decode_mime_words(self, s):\n        \"\"\"Decode MIME encoded words\"\"\"\n        if s is None:\n            return ''\n        \n        decoded_parts = []\n        for part, encoding in decode_header(s):\n            if isinstance(part, bytes):\n                if encoding:\n                    try:\n                        decoded_parts.append(part.decode(encoding))\n                    except:\n                        decoded_parts.append(part.decode('utf-8', errors='ignore'))\n                else:\n                    decoded_parts.append(part.decode('utf-8', errors='ignore'))\n            else:\n                decoded_parts.append(str(part))\n        \n        return ''.join(decoded_parts)\n    \n    def _format_time_ago(self, dt):\n        \"\"\"Convert datetime to 'X sec/min/hour/day' format\"\"\"\n        now = datetime.now(timezone.utc)\n        if dt.tzinfo is None:\n            dt = dt.replace(tzinfo=timezone.utc)\n        \n        diff = now - dt\n        seconds = int(diff.total_seconds())\n        \n        if seconds < 60:\n            return f\"{seconds} sec\"\n        elif seconds < 3600:\n            minutes = seconds // 60\n            return f\"{minutes} min\"\n        elif seconds < 86400:\n            hours = seconds // 3600\n            return f\"{hours} h\"\n        else:\n            days = seconds // 86400\n            return f\"{days} day{'s' if days > 1 else ''}\"\n    \n    def _get_gmail_folder_type_cached(self, uid, folder_name, category_uid_cache):\n        \"\"\"Determine Gmail folder type using cached category UIDs\"\"\"\n        if folder_name.lower() != 'inbox':\n            return folder_name\n        \n        # Check cached categories\n        categories = [\n            ('social', 'Inbox/Social'),\n            ('promotions', 'Inbox/Promotions'), \n            ('updates', 'Inbox/Updates'),\n            ('forums', 'Inbox/Forums')\n        ]\n        \n        for cat_key, folder_type in categories:\n            if uid in category_uid_cache.get(cat_key, set()):\n                return folder_type\n        \n        # Default to Primary if no category found\n        return 'Inbox/Primary'\n\n# Global connection manager instance\ngmail_manager = EntityBasedGmailManager()","path":null,"size_bytes":70244,"size_tokens":null},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"email-validator>=2.2.0\",\n    \"flask-login>=0.6.3\",\n    \"flask>=3.1.1\",\n    \"flask-sqlalchemy>=3.1.1\",\n    \"gunicorn>=23.0.0\",\n    \"psycopg2-binary>=2.9.10\",\n]\n","path":null,"size_bytes":306,"size_tokens":null},"style.css":{"content":"/* Custom styles for TSS Gmail Access */\n\n/* Enhanced hover effects */\n.email-row {\n    transition: all 0.2s ease-in-out;\n}\n\n.email-row:hover {\n    background-color: #f9fafb;\n    transform: translateY(-1px);\n    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n}\n\n/* Custom focus styles for better accessibility */\nselect:focus,\ninput:focus {\n    outline: none;\n    box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1);\n}\n\n/* Smooth transitions for form elements */\nselect,\ninput {\n    transition: all 0.2s ease-in-out;\n}\n\n/* Custom scrollbar for table */\n.overflow-x-auto::-webkit-scrollbar {\n    height: 6px;\n}\n\n.overflow-x-auto::-webkit-scrollbar-track {\n    background: #f1f5f9;\n    border-radius: 3px;\n}\n\n.overflow-x-auto::-webkit-scrollbar-thumb {\n    background: #cbd5e1;\n    border-radius: 3px;\n}\n\n.overflow-x-auto::-webkit-scrollbar-thumb:hover {\n    background: #94a3b8;\n}\n\n/* Loading animation for form submission */\n.loading {\n    position: relative;\n    overflow: hidden;\n}\n\n.loading::after {\n    content: '';\n    position: absolute;\n    top: 0;\n    left: -100%;\n    width: 100%;\n    height: 100%;\n    background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.4), transparent);\n    animation: loading 1.5s infinite;\n}\n\n@keyframes loading {\n    0% { left: -100%; }\n    100% { left: 100%; }\n}\n\n/* Responsive text truncation */\n@media (max-width: 640px) {\n    .max-w-xs {\n        max-width: 120px;\n    }\n    \n    .max-w-md {\n        max-width: 150px;\n    }\n}\n\n/* Enhanced badge styles */\n.inline-flex.items-center {\n    font-weight: 600;\n    letter-spacing: 0.025em;\n}\n\n/* Table header enhancements */\nthead th {\n    font-weight: 600;\n    letter-spacing: 0.05em;\n}\n\n/* Card shadow enhancements */\n.shadow-md {\n    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);\n}\n\n.shadow-sm {\n    box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);\n}\n\n/* Custom focus ring for better accessibility */\n.focus\\:ring-2:focus {\n    box-shadow: 0 0 0 2px var(--tw-ring-color);\n}\n\n/* Animated icons */\n.fas {\n    transition: transform 0.2s ease-in-out;\n}\n\n.hover\\:transform:hover .fas {\n    transform: scale(1.1);\n}\n\n/* Custom button hover effects */\nbutton:hover,\n.btn:hover {\n    transform: translateY(-1px);\n    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);\n}\n\n/* Gradient text effect for title */\n.text-gradient {\n    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n    -webkit-background-clip: text;\n    -webkit-text-fill-color: transparent;\n    background-clip: text;\n}\n\n/* Custom alert animations */\n.alert {\n    animation: slideInFromTop 0.3s ease-out;\n}\n\n@keyframes slideInFromTop {\n    0% {\n        transform: translateY(-20px);\n        opacity: 0;\n    }\n    100% {\n        transform: translateY(0);\n        opacity: 1;\n    }\n}\n\n/* Enhanced table styling */\ntbody tr {\n    border-bottom: 1px solid #e5e7eb;\n}\n\ntbody tr:last-child {\n    border-bottom: none;\n}\n\n/* Custom tooltip styles */\n[title]:hover::before {\n    content: attr(title);\n    position: absolute;\n    background: #374151;\n    color: white;\n    padding: 4px 8px;\n    border-radius: 4px;\n    font-size: 12px;\n    white-space: nowrap;\n    z-index: 1000;\n    transform: translateY(-100%);\n    margin-top: -8px;\n}\n\n/* Loading spinner for async operations */\n.spinner {\n    border: 2px solid #f3f4f6;\n    border-top: 2px solid #3b82f6;\n    border-radius: 50%;\n    width: 20px;\n    height: 20px;\n    animation: spin 1s linear infinite;\n    display: inline-block;\n    margin-right: 8px;\n}\n\n@keyframes spin {\n    0% { transform: rotate(0deg); }\n    100% { transform: rotate(360deg); }\n}\n\n/* Mobile optimizations */\n@media (max-width: 768px) {\n    .container {\n        padding-left: 1rem;\n        padding-right: 1rem;\n    }\n    \n    .text-4xl {\n        font-size: 2rem;\n    }\n    \n    .grid-cols-3 {\n        grid-template-columns: 1fr;\n    }\n}\n\n/* Email row specific styling */\n.email-row td {\n    vertical-align: middle;\n}\n\n/* Folder badge styling */\n.inline-flex.items-center.px-2\\.5 {\n    text-transform: uppercase;\n    font-size: 0.75rem;\n    font-weight: 700;\n}\n\n/* Form container styling */\nform {\n    background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%);\n    border-radius: 0.5rem;\n    padding: 1.5rem;\n    margin-bottom: 1rem;\n}\n\n/* Select dropdown custom styling */\nselect {\n    background-image: url(\"data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' fill='none' viewBox='0 0 20 20'%3e%3cpath stroke='%236b7280' stroke-linecap='round' stroke-linejoin='round' stroke-width='1.5' d='m6 8 4 4 4-4'/%3e%3c/svg%3e\");\n    background-position: right 0.5rem center;\n    background-repeat: no-repeat;\n    background-size: 1.5em 1.5em;\n    padding-right: 2.5rem;\n}\n\n/* Header title styling */\nh1 {\n    text-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n}\n\n/* Connection status styling */\n.bg-blue-50 {\n    background: linear-gradient(135deg, #eff6ff 0%, #dbeafe 100%);\n}\n\n.bg-red-50 {\n    background: linear-gradient(135deg, #fef2f2 0%, #fecaca 100%);\n}\n\n/* Table responsive styling */\n@media (max-width: 1024px) {\n    .overflow-x-auto {\n        display: block;\n        white-space: nowrap;\n    }\n    \n    table {\n        font-size: 0.875rem;\n    }\n    \n    th, td {\n        padding: 0.5rem 0.75rem;\n    }\n}\n\n/* Welcome section styling */\n.py-16 {\n    background: radial-gradient(ellipse at center, #f8fafc 0%, #e2e8f0 100%);\n    border-radius: 1rem;\n    margin: 2rem 0;\n}\n\n/* Feature cards styling */\n.grid .bg-white {\n    transition: all 0.3s ease;\n    border: 1px solid #e5e7eb;\n}\n\n.grid .bg-white:hover {\n    transform: translateY(-4px);\n    box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);\n    border-color: #3b82f6;\n}\n\n/* Icon styling in feature cards */\n.grid .fas {\n    opacity: 0.8;\n}\n\n.grid .bg-white:hover .fas {\n    opacity: 1;\n    transform: scale(1.2);\n}\n\n/* Loading state for form */\n.loading select {\n    opacity: 0.7;\n    pointer-events: none;\n}\n\n/* Enhanced focus states */\nselect:focus-visible,\nbutton:focus-visible {\n    outline: 2px solid #3b82f6;\n    outline-offset: 2px;\n}\n","path":null,"size_bytes":5995,"size_tokens":null},"app.py":{"content":"import os\nimport imaplib\nimport email\nimport email.utils\nfrom email.header import decode_header\nfrom datetime import datetime, timezone\nimport logging\nimport json\nimport re\nimport time\nimport dns.resolver\nfrom flask import Flask, render_template, request, flash, jsonify, redirect, url_for, session, Response\nfrom flask_login import LoginManager, UserMixin, login_user, logout_user, login_required, current_user\nfrom connection_manager import gmail_manager\n\n\nlogging.basicConfig(level=logging.DEBUG)\n\napp = Flask(__name__)\napp.secret_key = os.environ.get(\"SESSION_SECRET\")\n\n\nif not app.secret_key:\n    \n    app.secret_key = \"dev-secret-key-change-in-production\"\n    logging.warning(\"Using development fallback for SESSION_SECRET. Set SESSION_SECRET environment variable for production.\")\n\n\nlogin_manager = LoginManager()\nlogin_manager.init_app(app)\nlogin_manager.login_view = 'login'  # type: ignore\nlogin_manager.login_message = 'Please log in to access your emails.'\nlogin_manager.login_message_category = 'info'\n\n# User class for Flask-Login\nclass User(UserMixin):\n    def __init__(self, username, entity, name=None, has_toggle_permission=False, has_news_permission=False, has_domain_checker_permission=False, has_find_news_permission=False, has_extract_emails_permission=False):\n        self.id = username\n        self.username = username\n        self.entity = entity\n        self.name = name or username\n        self.has_toggle_permission = has_toggle_permission\n        self.has_news_permission = has_news_permission\n        self.has_domain_checker_permission = has_domain_checker_permission\n        self.has_find_news_permission = has_find_news_permission\n        self.has_extract_emails_permission = has_extract_emails_permission\n\n@login_manager.user_loader\ndef load_user(user_id):\n    \"\"\"Load user from session\"\"\"\n    users = load_users_from_file()\n    for user_data in users:\n        entity = user_data['entity']\n        name = user_data['name']\n        username = user_data['username']\n        has_toggle = user_data['has_toggle_permission']\n        has_news = user_data['has_news_permission']\n        has_domain_checker = user_data['has_domain_checker_permission']\n        has_find_news = user_data['has_find_news_permission']\n        has_extract_emails = user_data['has_extract_emails_permission']\n        if username == user_id:\n            return User(username, entity, name, has_toggle, has_news, has_domain_checker, has_find_news, has_extract_emails)\n    return None\n\ndef load_users_from_file():\n    \"\"\"Load users from users.txt file with new format: entity,Name,username,password[,permissions]\"\"\"\n    users = []\n    try:\n        with open('users.txt', 'r', encoding='utf-8') as f:\n            for line_num, line in enumerate(f, 1):\n                line = line.strip()\n                if line and not line.startswith('#'):\n                    try:\n                        parts = line.split(',')\n                        if len(parts) >= 4:\n                            entity = parts[0].strip()\n                            name = parts[1].strip()\n                            username = parts[2].strip()\n                            password = parts[3].strip()\n                            permissions = [p.strip() for p in parts[4:]] if len(parts) > 4 else []\n                            has_toggle = 'ok' in permissions\n                            has_news = 'allow_add_gmail_of_news' in permissions\n                            has_domain_checker = 'Domain_checker' in permissions\n                            has_find_news = 'find_news' in permissions\n                            has_extract_emails = 'Extract_emails' in permissions\n                            users.append({\n                                'entity': entity,\n                                'name': name,\n                                'username': username,\n                                'password': password,\n                                'permissions': permissions,\n                                'has_toggle_permission': has_toggle,\n                                'has_news_permission': has_news,\n                                'has_domain_checker_permission': has_domain_checker,\n                                'has_find_news_permission': has_find_news,\n                                'has_extract_emails_permission': has_extract_emails\n                            })\n                        else:\n                            logging.warning(f\"Invalid format in users.txt line {line_num}: {line}\")\n                    except Exception as e:\n                        logging.error(f\"Error parsing users.txt line {line_num}: {e}\")\n    except FileNotFoundError:\n        logging.error(\"users.txt file not found\")\n    except Exception as e:\n        logging.error(f\"Error reading users.txt: {e}\")\n    \n    return users\n\ndef get_user_accounts(user_entity):\n    \"\"\"Get Gmail accounts accessible to a user based on their entity\"\"\"\n    return gmail_manager.get_user_accounts(user_entity)\n\ndef authenticate_user(username, password):\n    \"\"\"Authenticate user against users.txt file and return user data dict\"\"\"\n    users = load_users_from_file()\n    for user_data in users:\n        if user_data['username'] == username and user_data['password'] == password:\n            return user_data\n    return None\n\ndef connect_to_gmail(email_addr, password):\n    \"\"\"Connect to Gmail using IMAP with enhanced error handling and validation\"\"\"\n    if not email_addr or not password:\n        logging.error(\"Email address and password are required\")\n        return None\n    \n    # Basic email validation\n    if '@' not in email_addr or '.' not in email_addr:\n        logging.error(f\"Invalid email address format: {email_addr}\")\n        return None\n        \n    try:\n        mail = imaplib.IMAP4_SSL('imap.gmail.com', 993)\n        mail.login(email_addr, password)\n        logging.info(f\"Successfully connected to Gmail account: {email_addr}\")\n        return mail\n    except imaplib.IMAP4.error as e:\n        logging.error(f\"IMAP authentication failed for {email_addr}: {e}\")\n        return None\n    except Exception as e:\n        logging.error(f\"Unexpected error connecting to Gmail {email_addr}: {e}\")\n        return None\n\ndef decode_mime_words(s):\n    \"\"\"Decode MIME encoded words\"\"\"\n    if s is None:\n        return ''\n    \n    decoded_parts = []\n    for part, encoding in decode_header(s):\n        if isinstance(part, bytes):\n            if encoding:\n                try:\n                    decoded_parts.append(part.decode(encoding))\n                except:\n                    decoded_parts.append(part.decode('utf-8', errors='ignore'))\n            else:\n                decoded_parts.append(part.decode('utf-8', errors='ignore'))\n        else:\n            decoded_parts.append(str(part))\n    \n    return ''.join(decoded_parts)\n\ndef extract_and_analyze_emails(email_address, app_password, email_limit='all', folder_selection='all'):\n    \"\"\"Extract and analyze emails with SPF, DKIM, IP address, and categorization - Optimized for speed\"\"\"\n    try:\n        # Connect to Gmail\n        mail = connect_to_gmail(email_address, app_password)\n        if not mail:\n            return None\n        \n        extracted_emails = []\n        \n        # Get folders to check based on user selection\n        if folder_selection == 'inbox':\n            folders_to_check = ['INBOX']\n        elif folder_selection == 'spam':\n            folders_to_check = ['[Gmail]/Spam']\n        else:  # folder_selection == 'all'\n            folders_to_check = ['INBOX', '[Gmail]/Spam']\n        \n        for folder in folders_to_check:\n            try:\n                mail.select(folder, readonly=True)  # Keep emails unread\n                \n                # Search for emails\n                result, message_ids = mail.uid('search', 'ALL')\n                if result != 'OK':\n                    continue\n                \n                uid_list = message_ids[0].split()\n                if not uid_list:\n                    continue\n                    \n                # Apply email limit based on user selection\n                if email_limit != 'all':\n                    try:\n                        limit = int(email_limit)  # No max limit restriction\n                        uid_list = uid_list[-limit:] if len(uid_list) > limit else uid_list\n                    except (ValueError, TypeError):\n                        # Default to 50 if invalid limit\n                        uid_list = uid_list[-50:] if len(uid_list) > 50 else uid_list\n                \n                # Pre-cache Gmail categories for inbox emails (only if needed)\n                category_cache = {}\n                if folder == 'INBOX':\n                    category_cache = _build_category_cache_fast(mail, uid_list)\n                \n                # BATCH OPTIMIZATION: Fetch emails in batches instead of one by one\n                # This reduces network round trips dramatically (500 requests  ~10 requests)\n                batch_size = 50  # Process 50 emails at once\n                total_emails = len(uid_list)\n                \n                for batch_start in range(0, total_emails, batch_size):\n                    batch_end = min(batch_start + batch_size, total_emails)\n                    batch_uids = uid_list[batch_start:batch_end]\n                    \n                    # Create UID range string for batch fetch\n                    # Decode bytes to string for IMAP command\n                    decoded_uids = [uid.decode() if isinstance(uid, bytes) else uid for uid in batch_uids]\n                    uid_range = ','.join(decoded_uids)\n                    \n                    try:\n                        # Fetch entire batch in ONE network request\n                        result, msg_data = mail.uid('fetch', uid_range, '(BODY.PEEK[HEADER])')\n                        if result != 'OK' or not msg_data:\n                            continue\n                        \n                        # Process all emails in this batch\n                        # msg_data is a list where each email is represented by a tuple (metadata, header_bytes)\n                        # with occasional trailing non-tuple items we can ignore\n                        for item in msg_data:\n                            # Skip non-tuple items (like closing parenthesis bytes)\n                            if not isinstance(item, tuple) or len(item) < 2:\n                                continue\n                                \n                            try:\n                                # Each tuple is (metadata_bytes, header_bytes)\n                                metadata = item[0]\n                                header_bytes = item[1]\n                                \n                                # Parse the UID from metadata\n                                # metadata looks like: b'123 (UID 456 BODY[HEADER] {1234}'\n                                uid_match = re.search(rb'UID (\\d+)', metadata) if isinstance(metadata, bytes) else None\n                                current_uid_bytes = uid_match.group(1) if uid_match else None\n                                \n                                # Skip if we can't parse UID or no header data\n                                if not current_uid_bytes or not header_bytes:\n                                    continue\n                                \n                                # Parse email headers\n                                email_message = email.message_from_bytes(header_bytes)\n                                \n                                # Extract basic info\n                                subject = decode_mime_words(email_message.get('Subject', ''))\n                                from_header = email_message.get('From', '')\n                                date_header = email_message.get('Date', '')\n                                \n                                # Parse from header\n                                from_name, from_email = email.utils.parseaddr(from_header)\n                                from_email = from_email.lower()\n                                from_domain_extracted = from_email.split('@')[-1] if '@' in from_email else ''\n                                \n                                # Extract security info from headers efficiently\n                                ip_address = extract_sender_ip_fast(email_message)\n                                spf_status = extract_spf_status(email_message)\n                                dkim_status = extract_dkim_status(email_message)\n                                dmarc_status = extract_dmarc_status(email_message)\n                                \n                                # Determine email type and category\n                                email_type = 'Spam' if folder == '[Gmail]/Spam' else 'Inbox'\n                                # Keep UID as bytes to match category_cache keys\n                                category = category_cache.get(current_uid_bytes, '') if folder == 'INBOX' else ''\n                                \n                                # Format date\n                                try:\n                                    parsed_date = email.utils.parsedate_to_datetime(date_header)\n                                    formatted_date = parsed_date.strftime('%Y-%m-%d %H:%M')\n                                except:\n                                    formatted_date = date_header[:50] if date_header else 'Unknown'\n                                \n                                extracted_emails.append({\n                                    'ip_address': ip_address,\n                                    'spf_status': spf_status,\n                                    'dkim_status': dkim_status,\n                                    'dmarc_status': dmarc_status,\n                                    'from_domain': from_domain_extracted,\n                                    'subject': subject[:100],\n                                    'email_type': email_type,\n                                    'category': category,\n                                    'date': formatted_date\n                                })\n                                \n                            except Exception as e:\n                                logging.error(f\"Error processing email in batch: {e}\")\n                                continue\n                                \n                    except Exception as e:\n                        logging.error(f\"Error fetching batch: {e}\")\n                        continue\n                        \n            except Exception as e:\n                logging.error(f\"Error accessing folder {folder}: {e}\")\n                continue\n        \n        mail.logout()\n        return extracted_emails\n        \n    except Exception as e:\n        logging.error(f\"Error in extract_and_analyze_emails: {e}\")\n        return None\n\ndef _build_category_cache_fast(mail, uid_list):\n    \"\"\"Build Gmail category cache using batch queries for speed\"\"\"\n    category_cache = {}\n    categories = ['social', 'promotions', 'updates', 'forums']\n    \n    for cat_key in categories:\n        try:\n            result, data = mail.uid('search', 'X-GM-RAW', f'\"category:{cat_key}\"')\n            if result == 'OK' and data[0]:\n                cat_uids = set(data[0].split())\n                for uid in uid_list:\n                    if uid in cat_uids:\n                        category_cache[uid] = cat_key.capitalize()\n        except Exception as e:\n            logging.debug(f\"Error caching category {cat_key}: {e}\")\n    \n    return category_cache\n\ndef extract_sender_ip_fast(email_message):\n    \"\"\"Optimized IP extraction - faster version\"\"\"\n    try:\n        # Check Received headers (most common location)\n        received_headers = email_message.get_all('Received', [])\n        \n        # Fast IP pattern matching\n        ip_pattern = re.compile(r'\\[(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\\]')\n        \n        for received in received_headers[:3]:  # Only check first 3 headers for speed\n            matches = ip_pattern.findall(received)\n            if matches:\n                # Return the first external IP (not private)\n                for ip in matches:\n                    if not ip.startswith(('10.', '192.168.', '172.16.', '172.17.', '172.18.', '172.19.', '172.20.', '172.21.', '172.22.', '172.23.', '172.24.', '172.25.', '172.26.', '172.27.', '172.28.', '172.29.', '172.30.', '172.31.')):\n                        return ip\n                # If no external IP, return first IP\n                return matches[0] if matches else None\n        \n        return None\n    except:\n        return None\n\ndef extract_sender_ip(email_message):\n    \"\"\"Extract sender IP address from email headers\"\"\"\n    try:\n        # Check various IP-containing headers\n        received_headers = email_message.get_all('Received', [])\n        \n        for received in received_headers:\n            # Look for IP addresses in Received headers\n\n            ip_pattern = r'\\[(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\\]'\n            matches = re.findall(ip_pattern, received)\n            if matches:\n                # Return the first external IP (not private)\n                for ip in matches:\n                    if not ip.startswith(('10.', '192.168.', '172.')):\n                        return ip\n                # If no external IP, return first IP\n                return matches[0] if matches else None\n        \n        return None\n    except:\n        return None\n\ndef extract_spf_status(email_message):\n    \"\"\"Extract SPF status from Authentication-Results header\"\"\"\n    try:\n        auth_results = email_message.get('Authentication-Results', '')\n        if 'spf=pass' in auth_results.lower():\n            return 'PASS'\n        elif 'spf=fail' in auth_results.lower():\n            return 'FAIL'\n        elif 'spf=softfail' in auth_results.lower():\n            return 'SOFTFAIL'\n        elif 'spf=neutral' in auth_results.lower():\n            return 'NEUTRAL'\n        elif 'spf=none' in auth_results.lower():\n            return 'NONE'\n        return 'UNKNOWN'\n    except:\n        return 'UNKNOWN'\n\ndef extract_dkim_status(email_message):\n    \"\"\"Extract DKIM status from Authentication-Results header\"\"\"\n    try:\n        auth_results = email_message.get('Authentication-Results', '')\n        if 'dkim=pass' in auth_results.lower():\n            return 'PASS'\n        elif 'dkim=fail' in auth_results.lower():\n            return 'FAIL'\n        elif 'dkim=neutral' in auth_results.lower():\n            return 'NEUTRAL'\n        elif 'dkim=none' in auth_results.lower():\n            return 'NONE'\n        return 'UNKNOWN'\n    except:\n        return 'UNKNOWN'\n\ndef extract_dmarc_status(email_message):\n    \"\"\"Extract DMARC status from Authentication-Results header\"\"\"\n    try:\n        auth_results = email_message.get('Authentication-Results', '')\n        if 'dmarc=pass' in auth_results.lower():\n            return 'PASS'\n        elif 'dmarc=fail' in auth_results.lower():\n            return 'FAIL'\n        elif 'dmarc=none' in auth_results.lower():\n            return 'NONE'\n        elif 'dmarc=quarantine' in auth_results.lower():\n            return 'QUARANTINE'\n        elif 'dmarc=reject' in auth_results.lower():\n            return 'REJECT'\n        return 'UNKNOWN'\n    except:\n        return 'UNKNOWN'\n\ndef get_gmail_category(mail, uid):\n    \"\"\"Get Gmail category for an email\"\"\"\n    try:\n        result, msg_data = mail.uid('fetch', uid, '(X-GM-LABELS)')\n        if result == 'OK' and msg_data and msg_data[0]:\n            labels_info = msg_data[0][1].decode('utf-8', errors='ignore') if isinstance(msg_data[0][1], bytes) else str(msg_data[0][1])\n            \n            if '\\\\\\\\Category\\\\\\\\Promotions' in labels_info or 'Category/Promotions' in labels_info:\n                return 'Promotions'\n            elif '\\\\\\\\Category\\\\\\\\Social' in labels_info or 'Category/Social' in labels_info:\n                return 'Social'\n            elif '\\\\\\\\Category\\\\\\\\Updates' in labels_info or 'Category/Updates' in labels_info:\n                return 'Updates'\n            elif '\\\\\\\\Category\\\\\\\\Forums' in labels_info or 'Category/Forums' in labels_info:\n                return 'Forums'\n            else:\n                return 'Primary'\n        return 'Primary'\n    except:\n        return 'Primary'\n\ndef get_improved_gmail_category(mail, uid):\n    \"\"\"Get Gmail category with improved detection using multiple methods\"\"\"\n    try:\n        # Method 1: Try X-GM-LABELS first (most reliable)\n        result, msg_data = mail.uid('fetch', uid, '(X-GM-LABELS)')\n        if result == 'OK' and msg_data and msg_data[0]:\n            labels_info = msg_data[0][1].decode('utf-8', errors='ignore') if isinstance(msg_data[0][1], bytes) else str(msg_data[0][1])\n            \n            # Check for various label formats\n            labels_lower = labels_info.lower()\n            if any(keyword in labels_lower for keyword in ['category\\\\\\\\promotions', 'category/promotions', '\"\\\\\\\\category\\\\\\\\promotions\"']):\n                return 'Promotions'\n            elif any(keyword in labels_lower for keyword in ['category\\\\\\\\social', 'category/social', '\"\\\\\\\\category\\\\\\\\social\"']):\n                return 'Social'\n            elif any(keyword in labels_lower for keyword in ['category\\\\\\\\updates', 'category/updates', '\"\\\\\\\\category\\\\\\\\updates\"']):\n                return 'Updates'\n            elif any(keyword in labels_lower for keyword in ['category\\\\\\\\forums', 'category/forums', '\"\\\\\\\\category\\\\\\\\forums\"']):\n                return 'Forums'\n        \n        # Method 2: Try Gmail search queries for categories\n        try:\n            # Check if email is in Promotions category using search\n            status, data = mail.uid('search', 'X-GM-RAW', f'\"category:promotions\"')\n            if status == 'OK' and data[0] and uid in data[0].split():\n                return 'Promotions'\n            \n            # Check Social category\n            status, data = mail.uid('search', 'X-GM-RAW', f'\"category:social\"')\n            if status == 'OK' and data[0] and uid in data[0].split():\n                return 'Social'\n            \n            # Check Updates category\n            status, data = mail.uid('search', 'X-GM-RAW', f'\"category:updates\"')\n            if status == 'OK' and data[0] and uid in data[0].split():\n                return 'Updates'\n            \n            # Check Forums category\n            status, data = mail.uid('search', 'X-GM-RAW', f'\"category:forums\"')\n            if status == 'OK' and data[0] and uid in data[0].split():\n                return 'Forums'\n            \n        except Exception as e:\n            logging.debug(f\"Gmail search method failed for UID {uid}: {e}\")\n        \n        # Method 3: Fall back to header analysis for common patterns\n        try:\n            result, msg_data = mail.uid('fetch', uid, '(BODY.PEEK[HEADER])')\n            if result == 'OK' and msg_data and msg_data[0]:\n                header_content = msg_data[0][1].decode('utf-8', errors='ignore').lower()\n                \n                # Look for promotional indicators\n                if any(keyword in header_content for keyword in ['unsubscribe', 'promotional', 'marketing', 'offer', 'deal']):\n                    return 'Promotions'\n                \n                # Look for social indicators\n                social_domains = ['facebook', 'twitter', 'linkedin', 'instagram', 'youtube', 'github']\n                if any(domain in header_content for domain in social_domains):\n                    return 'Social'\n                \n                # Look for update indicators\n                if any(keyword in header_content for keyword in ['newsletter', 'update', 'notification', 'alert']):\n                    return 'Updates'\n                \n        except Exception as e:\n            logging.debug(f\"Header analysis failed for UID {uid}: {e}\")\n        \n        return 'Primary'\n        \n    except Exception as e:\n        logging.debug(f\"Improved category detection failed for UID {uid}: {e}\")\n        return 'Primary'\n\ndef get_gmail_folder_type(mail, uid):\n    \"\"\"Determine Gmail folder type based only on authentic Gmail X-GM-LABELS\"\"\"\n    try:\n        # Only use Gmail's authentic X-GM-LABELS - no content analysis fallback\n        result, msg_data = mail.uid('fetch', uid, '(X-GM-LABELS)')\n        if result == 'OK' and msg_data and msg_data[0]:\n            try:\n                labels_info = msg_data[0][1].decode('utf-8', errors='ignore') if isinstance(msg_data[0][1], bytes) else str(msg_data[0][1])\n                logging.debug(f\"Gmail labels for UID {uid}: {labels_info}\")\n                \n                # Check for Gmail category labels - use exact Gmail format\n                if '\\\\\\\\Category\\\\\\\\Promotions' in labels_info or 'Category/Promotions' in labels_info:\n                    return 'Inbox/Promotions'\n                elif '\\\\\\\\Category\\\\\\\\Social' in labels_info or 'Category/Social' in labels_info:\n                    return 'Inbox/Social'\n                elif '\\\\\\\\Category\\\\\\\\Updates' in labels_info or 'Category/Updates' in labels_info:\n                    return 'Inbox/Updates'\n                elif '\\\\\\\\Category\\\\\\\\Forums' in labels_info or 'Category/Forums' in labels_info:\n                    return 'Inbox/Forums'\n                    \n            except Exception as e:\n                logging.debug(f\"Error parsing labels for UID {uid}: {e}\")\n            \n    except Exception as e:\n        logging.debug(f\"Error fetching labels for UID {uid}: {e}\")\n    \n    # Default to Primary if no Gmail category labels found\n    return 'Inbox/Primary'\n\n\n\n\n\ndef format_time_ago(dt):\n    \"\"\"Convert datetime to 'X sec/min/hour/day' (without 'ago')\"\"\"\n    now = datetime.now(timezone.utc)\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=timezone.utc)\n    \n    diff = now - dt\n    seconds = int(diff.total_seconds())\n    \n    if seconds < 60:\n        return f\"{seconds} sec\"\n    elif seconds < 3600:\n        minutes = seconds // 60\n        return f\"{minutes} min\"\n    elif seconds < 86400:\n        hours = seconds // 3600\n        return f\"{hours} h\"\n    else:\n        days = seconds // 86400\n        return f\"{days} day{'s' if days > 1 else ''}\"\n\n\n\n\n\n\n\n\n\ndef get_emails_from_folder(mail, folder, folder_name, limit=20):\n    \"\"\"Get emails with accurate Gmail category detection  only for Inbox\"\"\"\n    emails = []\n    \n    try:\n        # Select the folder\n        result = mail.select(folder)\n        if result[0] != 'OK':\n            return emails\n        \n        # Search for all UIDs\n        result, data = mail.uid('SEARCH', None, 'ALL')\n        if result != 'OK' or not data[0]:\n            return emails\n        \n        email_uids = data[0].split()\n        if not email_uids:\n            return emails\n        \n        # Take only the most recent ones\n        recent_uids = email_uids[-limit:]\n        recent_uids.reverse()\n\n        # === ONLY DETECT CATEGORIES IF THIS IS THE INBOX FOLDER ===\n        use_category_detection = folder_name.lower() == 'inbox'\n\n        # Cache for category UIDs (only if needed)\n        cat_uid_sets = {}\n        if use_category_detection:\n            categories = {\n                'social': 'Inbox/Social',\n                'promotions': 'Inbox/Promotions',\n                'updates': 'Inbox/Updates',\n                'forums': 'Inbox/Forums',\n                'purchases': 'Inbox/Purchases',\n                'reservations': 'Inbox/Reservations'\n            }\n\n            for cat_key in categories:\n                status, data = mail.uid('SEARCH', 'X-GM-RAW', f'\"category:{cat_key}\"')\n                cat_uid_sets[cat_key] = set(data[0].split()) if status == 'OK' and data[0] else set()\n        else:\n            # For non-Inbox folders, we don't need categories\n            pass\n\n        # === FETCH EMAILS ===\n        for uid in recent_uids:\n            try:\n                # Fetch only headers\n                result, msg_data = mail.uid('fetch', uid, '(BODY.PEEK[HEADER.FIELDS (FROM SUBJECT DATE)])')\n                if result != 'OK' or not msg_data[0]:\n                    continue\n\n                msg = email.message_from_bytes(msg_data[0][1])\n\n                from_header = msg.get('From', '')\n                from_name, from_email = email.utils.parseaddr(from_header)\n                from_name = decode_mime_words(from_name) if from_name else from_email\n\n                subject = decode_mime_words(msg.get('Subject', 'No Subject'))\n\n                date_header = msg.get('Date', '')\n                try:\n                    date_obj = email.utils.parsedate_to_datetime(date_header)\n                    date_timestamp = date_obj.timestamp()\n                    date_formatted = format_time_ago(date_obj)\n                except:\n                    date_timestamp = datetime.now().timestamp()\n                    date_formatted = 'Unknown'\n\n                # === DETERMINE FOLDER TYPE ===\n                if use_category_detection:\n                    # Only Inbox uses category tabs\n                    detected_folder = 'Inbox/Primary'\n                    for cat_key, folder_type_name in {\n                        'social': 'Inbox/Social',\n                        'promotions': 'Inbox/Promotions',\n                        'updates': 'Inbox/Updates',\n                        'forums': 'Inbox/Forums',\n                        'purchases': 'Inbox/Purchases',\n                        'reservations': 'Inbox/Reservations'\n                    }.items():\n                        if uid in cat_uid_sets[cat_key]:\n                            detected_folder = folder_type_name\n                            break\n                else:\n                    # Any other folder (Spam, Sent, etc.)  use folder name directly\n                    detected_folder = folder_name  # e.g., \"Spam\", \"Sent\", etc.\n\n                emails.append({\n                    'folder': detected_folder,\n                    'from_name': from_name,\n                    'from_email': from_email,\n                    'subject': subject,\n                    'title': subject,\n                    'date': date_timestamp,\n                    'date_formatted': date_formatted\n                })\n\n            except Exception as e:\n                logging.error(f\"Error processing email UID {uid}: {e}\")\n                continue\n\n    except Exception as e:\n        logging.error(f\"Error accessing folder {folder}: {e}\")\n    \n    return emails\n\n# Authentication Routes\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    if current_user.is_authenticated:\n        return redirect(url_for('dashboard'))\n    \n    if request.method == 'POST':\n        username = request.form.get('username', '').strip()\n        password = request.form.get('password', '').strip()\n        \n        if not username or not password:\n            flash('Please enter both username and password.', 'error')\n            return render_template('login.html')\n        \n        # Authenticate user\n        user_data = authenticate_user(username, password)\n        if user_data:\n            user_entity = user_data['entity']\n            user_name = user_data['name']\n            has_toggle = user_data['has_toggle_permission']\n            has_news = user_data['has_news_permission']\n            has_domain_checker = user_data['has_domain_checker_permission']\n            has_find_news = user_data['has_find_news_permission']\n            has_extract_emails = user_data['has_extract_emails_permission']\n            \n            user = User(username, user_entity, user_name, has_toggle, has_news, has_domain_checker, has_find_news, has_extract_emails)\n            login_user(user, remember=True)\n            \n            flash(f'Welcome, {user_name}!', 'success')\n            \n            # Redirect to next page if requested, otherwise services\n            next_page = request.args.get('next')\n            if next_page:\n                return redirect(next_page)\n            return redirect(url_for('services'))\n        else:\n            flash('Invalid username or password. Please try again.', 'error')\n    \n    return render_template('login.html')\n\n@app.route('/logout')\n@login_required\ndef logout():\n    username = current_user.username\n    logout_user()\n    flash(f'You have been logged out successfully, {username}.', 'info')\n    return redirect(url_for('login'))\n\n@app.route('/')\n@login_required\ndef index():\n    return redirect(url_for('services'))\n\n@app.route('/services')\n@login_required\ndef services():\n    \"\"\"Main services selection page\"\"\"\n    return render_template('services.html', current_user=current_user)\n\n@app.route('/extract_emails', methods=['GET', 'POST'])\n@login_required\ndef extract_emails():\n    \"\"\"TSS Extract Emails service\"\"\"\n    if not current_user.has_extract_emails_permission:\n        flash('You do not have permission to access the Extract Emails service.', 'error')\n        return redirect(url_for('services'))\n    \n    if request.method == 'GET':\n        return render_template('extract_emails.html', current_user=current_user)\n    \n    # Handle POST request for email extraction\n    try:\n        email_address = request.form.get('email_address', '').strip()\n        app_password = request.form.get('app_password', '').strip()\n        \n        # Validate required fields\n        if not email_address or not app_password:\n            return jsonify({'success': False, 'error': 'Email address and app password are required'})\n        \n        # Get email limit from form\n        email_limit = request.form.get('email_limit', 'all').strip()\n        if email_limit == 'limited':\n            custom_limit = request.form.get('custom_limit', '50').strip()\n            email_limit = custom_limit\n        \n        # Get folder selection\n        folder_selection = request.form.get('folder_selection', 'all')\n        \n        # Extract and analyze emails\n        extracted_data = extract_and_analyze_emails(email_address, app_password, email_limit, folder_selection)\n        \n        if extracted_data is None:\n            return jsonify({'success': False, 'error': 'Failed to connect to Gmail account. Please check your credentials.'})\n        \n        return jsonify({'success': True, 'data': extracted_data})\n        \n    except Exception as e:\n        logging.error(f\"Error in extract_emails: {e}\")\n        return jsonify({'success': False, 'error': f'Server error: {str(e)}'})\n\n@app.route('/dashboard', methods=['GET', 'POST'])\n@login_required\ndef dashboard():\n    selected_account = ''\n    emails = []\n    error = ''\n    email_limit = 50\n    search_sender = ''\n    search_subject = ''\n    \n    # Get accounts available to current user\n    user_accounts = get_user_accounts(current_user.entity)\n    \n    if request.method == 'POST':\n        # Input validation and sanitization\n        selected_account = request.form.get('account', '').strip()\n        try:\n            email_limit = int(request.form.get('email_limit', 50))\n            # Limit email_limit to reasonable bounds\n            email_limit = max(1, min(email_limit, 50))\n        except (ValueError, TypeError):\n            email_limit = 50\n            \n        search_sender = request.form.get('search_sender', '').strip()[:100]  # Limit length\n        search_subject = request.form.get('search_subject', '').strip()[:200]  # Limit length\n        \n        if selected_account and selected_account in user_accounts:\n            account_data = user_accounts[selected_account]\n            \n            # Handle TSSW account selection\n            if current_user.entity == 'TSSW':\n                gmail_manager.connect_tssw_account(current_user.username, selected_account)\n            \n            # Get emails from connection manager\n            emails = gmail_manager.get_emails(selected_account)\n            \n            if not emails:\n                error = f'Loading emails for {account_data[\"email\"]}... This may take a moment.'\n    \n    # Get account status information for toggle buttons\n    accounts_with_status = {}\n    if current_user.entity == 'TSSW' or current_user.has_toggle_permission:\n        accounts_status = gmail_manager.get_all_accounts_status(current_user.entity)\n        for account_key, account_info in user_accounts.items():\n            status_info = accounts_status.get(account_key, {})\n            accounts_with_status[account_key] = {\n                **account_info,\n                'connection_status': status_info.get('status', 'disconnected'),\n                'email_count': status_info.get('email_count', 0)\n            }\n    else:\n        # Regular users without toggle permissions - just basic account info\n        accounts_with_status = user_accounts\n    \n    return render_template('dashboard.html', \n                         accounts=accounts_with_status,\n                         selected_account=selected_account,\n                         emails=emails,\n                         error=error,\n                         email_limit=email_limit,\n                         search_sender=search_sender,\n                         search_subject=search_subject,\n                         current_user=current_user,\n                         show_toggles=(current_user.entity == 'TSSW' or current_user.has_toggle_permission))\n\n@app.route('/fetch_emails', methods=['POST'])\n@login_required\ndef fetch_emails():\n    \"\"\"API endpoint to fetch emails using connection manager\"\"\"\n    try:\n        data = request.get_json()\n        if not data:\n            return jsonify({'error': 'No data provided', 'emails': []})\n            \n        # Get accounts available to current user\n        user_accounts = get_user_accounts(current_user.entity)\n            \n        # Input validation and sanitization\n        selected_account = str(data.get('account', '')).strip()\n        try:\n            email_limit = int(data.get('email_limit', 50))\n            # Enforce reasonable bounds\n            email_limit = max(1, min(email_limit, 50))\n        except (ValueError, TypeError):\n            email_limit = 50\n            \n        search_sender = str(data.get('search_sender', ''))[:100]  # Limit length\n        search_subject = str(data.get('search_subject', ''))[:200]  # Limit length\n        \n        if not selected_account or selected_account not in user_accounts:\n            return jsonify({'error': 'Invalid account selected', 'emails': []})\n        \n        account_data = user_accounts[selected_account]\n        \n        # Handle TSSW account selection\n        if current_user.entity == 'TSSW':\n            gmail_manager.connect_tssw_account(current_user.username, selected_account)\n        \n        # Get emails from connection manager\n        emails = gmail_manager.get_emails(selected_account)\n        \n        return jsonify({\n            'error': '',\n            'emails': emails,\n            'email_count': len(emails),\n            'email_limit': email_limit,\n            'search_sender': search_sender,\n            'search_subject': search_subject\n        })\n            \n    except Exception as e:\n        logging.error(f\"Error in fetch_emails endpoint: {e}\")\n        return jsonify({'error': f'Server error: {str(e)}', 'emails': []})\n\n@app.route('/events/<account_key>')\n@login_required\ndef events(account_key):\n    \"\"\"Server-Sent Events endpoint for real-time email updates\"\"\"\n    # Verify user has access to this account\n    user_accounts = get_user_accounts(current_user.entity)\n    if account_key not in user_accounts:\n        return Response(\"Unauthorized\", status=403)\n    \n    # Handle TSSW account selection for events\n    if current_user.entity == 'TSSW':\n        gmail_manager.connect_tssw_account(current_user.username, account_key)\n    \n    def event_stream():\n        try:\n            # Queue to receive updates\n            import queue\n            update_queue = queue.Queue(maxsize=10)  # Limit queue size\n            \n            def callback(acc_key, emails):\n                if acc_key == account_key:\n                    try:\n                        update_queue.put_nowait(emails)\n                    except queue.Full:\n                        # Remove old items if queue is full\n                        try:\n                            update_queue.get_nowait()\n                            update_queue.put_nowait(emails)\n                        except:\n                            pass\n            \n            # Add callback to connection manager\n            gmail_manager.add_update_callback(account_key, callback)\n            \n            # Send initial data\n            emails = gmail_manager.get_emails(account_key)\n            yield f\"data: {json.dumps({'emails': emails if emails else []})}\\n\\n\"\n            \n            # Listen for updates with timeout limit\n            heartbeat_count = 0\n            max_heartbeats = 20  # Max 10 minutes of heartbeats\n            \n            while heartbeat_count < max_heartbeats:\n                try:\n                    emails = update_queue.get(timeout=15)  # Reduced timeout\n                    yield f\"data: {json.dumps({'emails': emails if emails else []})}\\n\\n\"\n                    heartbeat_count = 0  # Reset heartbeat count on successful update\n                except queue.Empty:\n                    # Send heartbeat\n                    heartbeat_count += 1\n                    yield f\"data: {json.dumps({'heartbeat': True, 'count': heartbeat_count})}\\n\\n\"\n                    \n        except Exception as e:\n            logging.error(f\"Error in event stream for {account_key}: {e}\")\n            yield f\"data: {json.dumps({'error': str(e), 'account': account_key})}\\n\\n\"\n    \n    return Response(event_stream(), mimetype='text/event-stream')\n\n@app.route('/api/toggle_account', methods=['POST'])\n@login_required\ndef toggle_account():\n    \"\"\"API endpoint to toggle Gmail account connection\"\"\"\n    try:\n        data = request.get_json()\n        account_key = data.get('account_key')\n        force_state = data.get('force_state')  # 'on' or 'off' or None for toggle\n        \n        if not account_key:\n            return jsonify({'success': False, 'error': 'Account key required'}), 400\n        \n        # Check permissions\n        if current_user.entity != 'TSSW' and not current_user.has_toggle_permission:\n            return jsonify({'success': False, 'error': 'Permission denied'}), 403\n        \n        # Verify user has access to this account\n        user_accounts = get_user_accounts(current_user.entity)\n        if account_key not in user_accounts:\n            return jsonify({'success': False, 'error': 'Account not found'}), 404\n        \n        # Toggle the account\n        success = gmail_manager.toggle_account_connection(\n            current_user.username,\n            current_user.entity, \n            account_key,\n            force_state\n        )\n        \n        if success:\n            # Get updated status\n            new_status = gmail_manager.get_account_connection_status(account_key)\n            return jsonify({\n                'success': True,\n                'new_status': new_status,\n                'account_key': account_key\n            })\n        else:\n            return jsonify({'success': False, 'error': 'Failed to toggle account'}), 500\n            \n    except Exception as e:\n        logging.error(f\"Error toggling account: {e}\")\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n@app.route('/api/account_status/<account_key>')\n@login_required  \ndef get_account_status(account_key):\n    \"\"\"API endpoint to get account connection status\"\"\"\n    try:\n        # Check permissions\n        if current_user.entity != 'TSSW' and not current_user.has_toggle_permission:\n            return jsonify({'error': 'Permission denied'}), 403\n        \n        # Verify user has access to this account\n        user_accounts = get_user_accounts(current_user.entity)\n        if account_key not in user_accounts:\n            return jsonify({'error': 'Account not found'}), 404\n        \n        status = gmail_manager.get_account_connection_status(account_key)\n        email_count = len(gmail_manager.get_emails(account_key))\n        \n        return jsonify({\n            'account_key': account_key,\n            'status': status,\n            'email_count': email_count\n        })\n        \n    except Exception as e:\n        logging.error(f\"Error getting account status: {e}\")\n        return jsonify({'error': str(e)}), 500\n\n# Removed - entity-based connections don't need individual unsubscribe\n\n@app.route('/find_news')\n@login_required\ndef find_news():\n    \"\"\"Find News dashboard - displays news Gmail accounts\"\"\"\n    if not current_user.has_find_news_permission:\n        flash('You do not have permission to access the Find News service.', 'error')\n        return redirect(url_for('services'))\n    \n    news_accounts = gmail_manager.get_news_accounts(current_user.entity)\n    \n    # Get list of entities for TSSW users (they can add accounts to any entity)\n    entities = []\n    if current_user.entity.upper() == 'TSSW':\n        entities = ['TSS1', 'TSS2', 'TSS3', 'TSSF', 'TSSW']\n    \n    return render_template('find_news.html', \n                         accounts=news_accounts,\n                         selected_account=None,\n                         can_manage_news=current_user.has_news_permission,\n                         entities=entities,\n                         user_entity=current_user.entity.upper())\n\ndef load_news_accounts_for_management(user_entity):\n    \"\"\"Load news accounts that a user can manage (from their entity or all if TSSW)\"\"\"\n    accounts = []\n    try:\n        with open('gmailaccounts.txt', 'r', encoding='utf-8') as f:\n            for line_num, line in enumerate(f, 1):\n                line = line.strip()\n                if line and not line.startswith('#'):\n                    parts = line.split(',')\n                    if len(parts) >= 4 and parts[3].strip().lower() == 'news':\n                        entity = parts[0].strip().upper()\n                        email_addr = parts[1].strip()\n                        app_password = parts[2].strip()\n                        \n                        # TSSW can see all, others only their entity\n                        if user_entity.upper() == 'TSSW' or entity == user_entity.upper():\n                            accounts.append({\n                                'entity': entity,\n                                'email': email_addr,\n                                'app_password': app_password,\n                                'line_num': line_num\n                            })\n    except FileNotFoundError:\n        logging.error(\"gmailaccounts.txt file not found\")\n    except Exception as e:\n        logging.error(f\"Error reading gmailaccounts.txt: {e}\")\n    return accounts\n\ndef save_news_account(entity, email, app_password):\n    \"\"\"Add a new news Gmail account to gmailaccounts.txt\"\"\"\n    try:\n        with open('gmailaccounts.txt', 'a', encoding='utf-8') as f:\n            f.write(f\"\\n{entity},{email},{app_password},news\")\n        gmail_manager.load_gmail_accounts()\n        return True\n    except Exception as e:\n        logging.error(f\"Error saving news account: {e}\")\n        return False\n\ndef update_news_account(old_entity, old_email, new_entity, new_email, new_password):\n    \"\"\"Update an existing news Gmail account in gmailaccounts.txt\"\"\"\n    try:\n        lines = []\n        found = False\n        with open('gmailaccounts.txt', 'r', encoding='utf-8') as f:\n            for line in f:\n                stripped = line.strip()\n                if stripped and not stripped.startswith('#'):\n                    parts = stripped.split(',')\n                    if len(parts) >= 4 and parts[3].strip().lower() == 'news':\n                        if parts[0].strip().upper() == old_entity.upper() and parts[1].strip() == old_email:\n                            lines.append(f\"{new_entity},{new_email},{new_password},news\\n\")\n                            found = True\n                            continue\n                lines.append(line if line.endswith('\\n') else line + '\\n')\n        \n        if found:\n            with open('gmailaccounts.txt', 'w', encoding='utf-8') as f:\n                f.writelines(lines)\n            gmail_manager.load_gmail_accounts()\n        return found\n    except Exception as e:\n        logging.error(f\"Error updating news account: {e}\")\n        return False\n\ndef delete_news_account(entity, email):\n    \"\"\"Delete a news Gmail account from gmailaccounts.txt\"\"\"\n    try:\n        lines = []\n        found = False\n        with open('gmailaccounts.txt', 'r', encoding='utf-8') as f:\n            for line in f:\n                stripped = line.strip()\n                if stripped and not stripped.startswith('#'):\n                    parts = stripped.split(',')\n                    if len(parts) >= 4 and parts[3].strip().lower() == 'news':\n                        if parts[0].strip().upper() == entity.upper() and parts[1].strip() == email:\n                            found = True\n                            continue\n                lines.append(line if line.endswith('\\n') else line + '\\n')\n        \n        if found:\n            with open('gmailaccounts.txt', 'w', encoding='utf-8') as f:\n                f.writelines(lines)\n            gmail_manager.load_gmail_accounts()\n        return found\n    except Exception as e:\n        logging.error(f\"Error deleting news account: {e}\")\n        return False\n\ndef load_extraction_accounts():\n    \"\"\"Load Gmail accounts with allow_extraction flag for TSSW users\"\"\"\n    accounts = []\n    try:\n        with open('gmailaccounts.txt', 'r', encoding='utf-8') as f:\n            for line_num, line in enumerate(f, 1):\n                line = line.strip()\n                if line and not line.startswith('#'):\n                    parts = line.split(',')\n                    if len(parts) >= 4 and parts[3].strip().lower() == 'allow_extraction':\n                        entity = parts[0].strip().upper()\n                        email_addr = parts[1].strip()\n                        app_password = parts[2].strip()\n                        accounts.append({\n                            'entity': entity,\n                            'email': email_addr,\n                            'app_password': app_password,\n                            'line_num': line_num\n                        })\n    except FileNotFoundError:\n        logging.error(\"gmailaccounts.txt file not found\")\n    except Exception as e:\n        logging.error(f\"Error reading gmailaccounts.txt: {e}\")\n    return accounts\n\ndef save_extraction_account(email, app_password):\n    \"\"\"Add a new extraction Gmail account to gmailaccounts.txt\"\"\"\n    try:\n        with open('gmailaccounts.txt', 'a', encoding='utf-8') as f:\n            f.write(f\"\\nEXTRACTION,{email},{app_password},allow_extraction\")\n        gmail_manager.load_gmail_accounts()\n        return True\n    except Exception as e:\n        logging.error(f\"Error saving extraction account: {e}\")\n        return False\n\ndef update_extraction_account(old_email, new_email, new_password):\n    \"\"\"Update an existing extraction Gmail account in gmailaccounts.txt\"\"\"\n    try:\n        lines = []\n        found = False\n        with open('gmailaccounts.txt', 'r', encoding='utf-8') as f:\n            for line in f:\n                stripped = line.strip()\n                if stripped and not stripped.startswith('#'):\n                    parts = stripped.split(',')\n                    if len(parts) >= 4 and parts[3].strip().lower() == 'allow_extraction':\n                        if parts[1].strip() == old_email:\n                            entity = parts[0].strip()\n                            lines.append(f\"{entity},{new_email},{new_password},allow_extraction\\n\")\n                            found = True\n                            continue\n                lines.append(line if line.endswith('\\n') else line + '\\n')\n        \n        if found:\n            with open('gmailaccounts.txt', 'w', encoding='utf-8') as f:\n                f.writelines(lines)\n            gmail_manager.load_gmail_accounts()\n        return found\n    except Exception as e:\n        logging.error(f\"Error updating extraction account: {e}\")\n        return False\n\ndef delete_extraction_account(email):\n    \"\"\"Delete an extraction Gmail account from gmailaccounts.txt\"\"\"\n    try:\n        lines = []\n        found = False\n        with open('gmailaccounts.txt', 'r', encoding='utf-8') as f:\n            for line in f:\n                stripped = line.strip()\n                if stripped and not stripped.startswith('#'):\n                    parts = stripped.split(',')\n                    if len(parts) >= 4 and parts[3].strip().lower() == 'allow_extraction':\n                        if parts[1].strip() == email:\n                            found = True\n                            continue\n                lines.append(line if line.endswith('\\n') else line + '\\n')\n        \n        if found:\n            with open('gmailaccounts.txt', 'w', encoding='utf-8') as f:\n                f.writelines(lines)\n            gmail_manager.load_gmail_accounts()\n        return found\n    except Exception as e:\n        logging.error(f\"Error deleting extraction account: {e}\")\n        return False\n\n@app.route('/api/extraction_accounts', methods=['GET'])\n@login_required\ndef get_extraction_accounts():\n    \"\"\"Get extraction accounts for TSSW users\"\"\"\n    if current_user.entity.upper() != 'TSSW':\n        return jsonify({'error': 'Permission denied'}), 403\n    \n    accounts = load_extraction_accounts()\n    return jsonify({'success': True, 'accounts': accounts})\n\n@app.route('/api/extraction_accounts', methods=['POST'])\n@login_required\ndef add_extraction_account():\n    \"\"\"Add a new extraction Gmail account\"\"\"\n    if current_user.entity.upper() != 'TSSW':\n        return jsonify({'error': 'Permission denied'}), 403\n    \n    data = request.get_json()\n    email = data.get('email', '').strip()\n    app_password = data.get('app_password', '').strip()\n    \n    if not email or not app_password:\n        return jsonify({'error': 'Email and app password are required'}), 400\n    \n    if '@' not in email or '.' not in email:\n        return jsonify({'error': 'Invalid email format'}), 400\n    \n    if save_extraction_account(email, app_password):\n        return jsonify({'success': True, 'message': 'Account added successfully'})\n    else:\n        return jsonify({'error': 'Failed to add account'}), 500\n\n@app.route('/api/extraction_accounts', methods=['PUT'])\n@login_required\ndef update_extraction_account_route():\n    \"\"\"Update an existing extraction Gmail account\"\"\"\n    if current_user.entity.upper() != 'TSSW':\n        return jsonify({'error': 'Permission denied'}), 403\n    \n    data = request.get_json()\n    old_email = data.get('old_email', '').strip()\n    new_email = data.get('email', '').strip()\n    new_password = data.get('app_password', '').strip()\n    \n    if not all([old_email, new_email, new_password]):\n        return jsonify({'error': 'All fields are required'}), 400\n    \n    if update_extraction_account(old_email, new_email, new_password):\n        return jsonify({'success': True, 'message': 'Account updated successfully'})\n    else:\n        return jsonify({'error': 'Account not found or update failed'}), 404\n\n@app.route('/api/extraction_accounts', methods=['DELETE'])\n@login_required\ndef delete_extraction_account_route():\n    \"\"\"Delete an extraction Gmail account\"\"\"\n    if current_user.entity.upper() != 'TSSW':\n        return jsonify({'error': 'Permission denied'}), 403\n    \n    data = request.get_json()\n    email = data.get('email', '').strip()\n    \n    if not email:\n        return jsonify({'error': 'Email is required'}), 400\n    \n    if delete_extraction_account(email):\n        return jsonify({'success': True, 'message': 'Account deleted successfully'})\n    else:\n        return jsonify({'error': 'Account not found or delete failed'}), 404\n\n@app.route('/api/news_accounts', methods=['GET'])\n@login_required\ndef get_manageable_news_accounts():\n    \"\"\"Get news accounts that the current user can manage\"\"\"\n    if not current_user.has_news_permission:\n        return jsonify({'error': 'Permission denied'}), 403\n    \n    accounts = load_news_accounts_for_management(current_user.entity)\n    return jsonify({'success': True, 'accounts': accounts})\n\n@app.route('/api/news_accounts', methods=['POST'])\n@login_required\ndef add_news_account():\n    \"\"\"Add a new news Gmail account\"\"\"\n    if not current_user.has_news_permission:\n        return jsonify({'error': 'Permission denied'}), 403\n    \n    data = request.get_json()\n    entity = data.get('entity', '').strip().upper()\n    email = data.get('email', '').strip()\n    app_password = data.get('app_password', '').strip()\n    \n    if not entity or not email or not app_password:\n        return jsonify({'error': 'All fields are required'}), 400\n    \n    # Non-TSSW users can only add to their own entity\n    if current_user.entity.upper() != 'TSSW' and entity != current_user.entity.upper():\n        return jsonify({'error': 'You can only add accounts to your own entity'}), 403\n    \n    # Validate email format\n    if '@' not in email or '.' not in email:\n        return jsonify({'error': 'Invalid email format'}), 400\n    \n    if save_news_account(entity, email, app_password):\n        return jsonify({'success': True, 'message': 'Account added successfully'})\n    else:\n        return jsonify({'error': 'Failed to add account'}), 500\n\n@app.route('/api/news_accounts', methods=['PUT'])\n@login_required\ndef update_news_account_route():\n    \"\"\"Update an existing news Gmail account\"\"\"\n    if not current_user.has_news_permission:\n        return jsonify({'error': 'Permission denied'}), 403\n    \n    data = request.get_json()\n    old_entity = data.get('old_entity', '').strip().upper()\n    old_email = data.get('old_email', '').strip()\n    new_entity = data.get('entity', '').strip().upper()\n    new_email = data.get('email', '').strip()\n    new_password = data.get('app_password', '').strip()\n    \n    if not all([old_entity, old_email, new_entity, new_email, new_password]):\n        return jsonify({'error': 'All fields are required'}), 400\n    \n    # Check permissions\n    if current_user.entity.upper() != 'TSSW':\n        if old_entity != current_user.entity.upper() or new_entity != current_user.entity.upper():\n            return jsonify({'error': 'You can only modify accounts in your own entity'}), 403\n    \n    if update_news_account(old_entity, old_email, new_entity, new_email, new_password):\n        return jsonify({'success': True, 'message': 'Account updated successfully'})\n    else:\n        return jsonify({'error': 'Account not found or update failed'}), 404\n\n@app.route('/api/news_accounts', methods=['DELETE'])\n@login_required\ndef delete_news_account_route():\n    \"\"\"Delete a news Gmail account\"\"\"\n    if not current_user.has_news_permission:\n        return jsonify({'error': 'Permission denied'}), 403\n    \n    data = request.get_json()\n    entity = data.get('entity', '').strip().upper()\n    email = data.get('email', '').strip()\n    \n    if not entity or not email:\n        return jsonify({'error': 'Entity and email are required'}), 400\n    \n    # Check permissions\n    if current_user.entity.upper() != 'TSSW' and entity != current_user.entity.upper():\n        return jsonify({'error': 'You can only delete accounts from your own entity'}), 403\n    \n    if delete_news_account(entity, email):\n        return jsonify({'success': True, 'message': 'Account deleted successfully'})\n    else:\n        return jsonify({'error': 'Account not found or delete failed'}), 404\n\n@app.route('/api/news_emails/<account_key>')\n@login_required\ndef get_news_emails(account_key):\n    \"\"\"Fetch last 50 inbox emails for a news account\"\"\"\n    try:\n        news_accounts = gmail_manager.get_news_accounts(current_user.entity)\n        if account_key not in news_accounts:\n            return jsonify({'error': 'Account not found or unauthorized'}), 404\n        \n        account = news_accounts[account_key]\n        emails = fetch_news_emails_fast(account['email'], account['app_password'], limit=50)\n        \n        return jsonify({\n            'success': True,\n            'emails': emails,\n            'account_key': account_key\n        })\n    except Exception as e:\n        logging.error(f\"Error fetching news emails: {e}\")\n        return jsonify({'error': str(e)}), 500\n\n@app.route('/api/email_source/<account_key>/<uid>')\n@login_required\ndef get_email_source(account_key, uid):\n    \"\"\"Get full email source (headers, MIME parts) for copying\"\"\"\n    try:\n        news_accounts = gmail_manager.get_news_accounts(current_user.entity)\n        if account_key not in news_accounts:\n            return jsonify({'error': 'Account not found or unauthorized'}), 404\n        \n        account = news_accounts[account_key]\n        source = fetch_email_source(account['email'], account['app_password'], uid)\n        \n        if source:\n            return jsonify({\n                'success': True,\n                'source': source,\n                'uid': uid\n            })\n        else:\n            return jsonify({'error': 'Email not found'}), 404\n    except Exception as e:\n        logging.error(f\"Error fetching email source: {e}\")\n        return jsonify({'error': str(e)}), 500\n\n@app.route('/news_events/<account_key>')\n@login_required\ndef news_events(account_key):\n    \"\"\"Server-Sent Events for real-time news email updates\"\"\"\n    news_accounts = gmail_manager.get_news_accounts(current_user.entity)\n    if account_key not in news_accounts:\n        return Response(\"Unauthorized\", status=403)\n    \n    account = news_accounts[account_key]\n    \n    def event_stream():\n        try:\n            last_check_time = 0\n            check_interval = 10  # Check every 10 seconds for new emails\n            \n            while True:\n                current_time = time.time()\n                \n                if current_time - last_check_time >= check_interval:\n                    try:\n                        emails = fetch_news_emails_fast(account['email'], account['app_password'], limit=50)\n                        yield f\"data: {json.dumps({'emails': emails, 'timestamp': current_time})}\\n\\n\"\n                        last_check_time = current_time\n                    except Exception as e:\n                        logging.error(f\"Error fetching news emails in SSE: {e}\")\n                        yield f\"data: {json.dumps({'error': str(e)})}\\n\\n\"\n                else:\n                    # Send heartbeat\n                    yield f\"data: {json.dumps({'heartbeat': True})}\\n\\n\"\n                \n                time.sleep(5)  # Sleep 5 seconds between checks\n                \n        except Exception as e:\n            logging.error(f\"Error in news event stream: {e}\")\n            yield f\"data: {json.dumps({'error': str(e)})}\\n\\n\"\n    \n    return Response(event_stream(), mimetype='text/event-stream')\n\ndef fetch_news_emails_fast(email_addr, app_password, limit=50):\n    \"\"\"Fetch last N inbox emails quickly (excluding spam) with Gmail folder/category info\"\"\"\n    emails = []\n    mail = None\n    try:\n        mail = imaplib.IMAP4_SSL('imap.gmail.com', 993)\n        mail.login(email_addr, app_password)\n        mail.select('INBOX')\n        \n        result, data = mail.uid('SEARCH', None, 'ALL')\n        if result != 'OK' or not data[0]:\n            return emails\n        \n        email_uids = data[0].split()\n        if not email_uids:\n            return emails\n        \n        recent_uids = email_uids[-limit:]\n        recent_uids.reverse()\n        \n        category_cache = {}\n        categories = ['social', 'promotions', 'updates', 'forums']\n        for cat_key in categories:\n            try:\n                result_cat, data_cat = mail.uid('search', 'X-GM-RAW', f'\"category:{cat_key}\"')\n                if result_cat == 'OK' and data_cat[0]:\n                    cat_uids = set(data_cat[0].split())\n                    for uid in recent_uids:\n                        if uid in cat_uids:\n                            category_cache[uid] = cat_key.capitalize()\n            except Exception as e:\n                logging.debug(f\"Error caching category {cat_key}: {e}\")\n        \n        for uid in recent_uids:\n            try:\n                uid_str = uid.decode() if isinstance(uid, bytes) else str(uid)\n                result, msg_data = mail.uid('fetch', uid, '(BODY.PEEK[HEADER.FIELDS (FROM SUBJECT DATE)])')\n                if result != 'OK' or not msg_data[0]:\n                    continue\n                \n                msg = email.message_from_bytes(msg_data[0][1])\n                \n                from_header = msg.get('From', '')\n                from_name, from_email_addr = email.utils.parseaddr(from_header)\n                from_name = decode_mime_words(from_name) if from_name else from_email_addr\n                \n                from_domain = ''\n                if '@' in from_email_addr:\n                    from_domain = from_email_addr.split('@')[1]\n                \n                subject = decode_mime_words(msg.get('Subject', 'No Subject'))\n                \n                date_header = msg.get('Date', '')\n                try:\n                    date_obj = email.utils.parsedate_to_datetime(date_header)\n                    date_str = date_obj.strftime('%Y-%m-%d %H:%M')\n                except:\n                    date_str = date_header[:20] if date_header else 'Unknown'\n                \n                folder = category_cache.get(uid, 'Primary')\n                \n                emails.append({\n                    'uid': uid_str,\n                    'subject': subject[:100] if len(subject) > 100 else subject,\n                    'from_name': from_name[:50] if len(from_name) > 50 else from_name,\n                    'from_domain': from_domain,\n                    'date': date_str,\n                    'folder': folder\n                })\n                \n            except Exception as e:\n                logging.debug(f\"Error processing email UID {uid}: {e}\")\n                continue\n                \n    except Exception as e:\n        logging.error(f\"Error in fetch_news_emails_fast: {e}\")\n    finally:\n        if mail:\n            try:\n                mail.logout()\n            except:\n                pass\n    \n    return emails\n\ndef fetch_email_source(email_addr, app_password, uid):\n    \"\"\"Fetch full email source (headers + body + MIME parts)\"\"\"\n    mail = None\n    try:\n        mail = imaplib.IMAP4_SSL('imap.gmail.com', 993)\n        mail.login(email_addr, app_password)\n        mail.select('INBOX')\n        \n        result, msg_data = mail.uid('fetch', uid, '(RFC822)')\n        if result != 'OK' or not msg_data[0]:\n            return None\n        \n        raw_email = msg_data[0][1]\n        if isinstance(raw_email, bytes):\n            return raw_email.decode('utf-8', errors='replace')\n        return str(raw_email)\n        \n    except Exception as e:\n        logging.error(f\"Error fetching email source: {e}\")\n        return None\n    finally:\n        if mail:\n            try:\n                mail.logout()\n            except:\n                pass\n\ndef get_dns_resolver():\n    \"\"\"Get a configured DNS resolver with timeout and reliable nameservers\"\"\"\n    resolver = dns.resolver.Resolver()\n    resolver.timeout = 5\n    resolver.lifetime = 10\n    resolver.nameservers = ['8.8.8.8', '8.8.4.4', '1.1.1.1']\n    return resolver\n\ndef lookup_dmarc(domain):\n    \"\"\"Lookup DMARC record for a domain\"\"\"\n    try:\n        resolver = get_dns_resolver()\n        dmarc_domain = f\"_dmarc.{domain}\"\n        answers = resolver.resolve(dmarc_domain, 'TXT')\n        for rdata in answers:\n            txt_parts = []\n            for s in rdata.strings:\n                if isinstance(s, bytes):\n                    txt_parts.append(s.decode('utf-8', errors='replace'))\n                else:\n                    txt_parts.append(str(s))\n            txt_value = ''.join(txt_parts)\n            if txt_value.lower().startswith('v=dmarc1'):\n                return txt_value\n        return None\n    except (dns.resolver.NXDOMAIN, dns.resolver.NoAnswer, dns.resolver.NoNameservers, dns.resolver.Timeout):\n        return None\n    except Exception as e:\n        logging.debug(f\"DMARC lookup error for {domain}: {e}\")\n        return None\n\ndef lookup_mx(domain):\n    \"\"\"Lookup MX records for a domain\"\"\"\n    try:\n        resolver = get_dns_resolver()\n        answers = resolver.resolve(domain, 'MX')\n        mx_records = []\n        for rdata in answers:\n            mx_records.append(f\"{rdata.preference} {rdata.exchange}\")\n        return mx_records\n    except (dns.resolver.NXDOMAIN, dns.resolver.NoAnswer, dns.resolver.NoNameservers, dns.resolver.Timeout):\n        return None\n    except Exception as e:\n        logging.debug(f\"MX lookup error for {domain}: {e}\")\n        return None\n\ndef lookup_txt(domain):\n    \"\"\"Lookup TXT records for a domain\"\"\"\n    try:\n        resolver = get_dns_resolver()\n        answers = resolver.resolve(domain, 'TXT')\n        txt_records = []\n        for rdata in answers:\n            txt_parts = []\n            for s in rdata.strings:\n                if isinstance(s, bytes):\n                    txt_parts.append(s.decode('utf-8', errors='replace'))\n                else:\n                    txt_parts.append(str(s))\n            txt_records.append(''.join(txt_parts))\n        return txt_records\n    except (dns.resolver.NXDOMAIN, dns.resolver.NoAnswer, dns.resolver.NoNameservers, dns.resolver.Timeout):\n        return None\n    except Exception as e:\n        logging.debug(f\"TXT lookup error for {domain}: {e}\")\n        return None\n\ndef is_valid_ip(ip):\n    \"\"\"Check if a string is a valid IPv4 address\"\"\"\n    pattern = r'^(\\d{1,3}\\.){3}\\d{1,3}$'\n    if not re.match(pattern, ip):\n        return False\n    parts = ip.split('.')\n    return all(0 <= int(part) <= 255 for part in parts)\n\n@app.route('/domain_checker')\n@login_required\ndef domain_checker():\n    \"\"\"Domain checker service - DNS lookup tools\"\"\"\n    if not current_user.has_domain_checker_permission:\n        flash('You do not have permission to access the Domain Checker service.', 'error')\n        return redirect(url_for('services'))\n    return render_template('domain_checker.html')\n\n@app.route('/api/domain_checker/dmarc', methods=['POST'])\n@login_required\ndef api_dmarc_lookup():\n    \"\"\"API endpoint for DMARC lookups\"\"\"\n    if not current_user.has_domain_checker_permission:\n        return jsonify({'error': 'Permission denied'}), 403\n    \n    data = request.get_json()\n    domains_text = data.get('domains', '')\n    \n    domains = [d.strip().lower() for d in domains_text.strip().split('\\n') if d.strip()]\n    \n    results = []\n    for domain in domains:\n        dmarc_record = lookup_dmarc(domain)\n        results.append({\n            'domain': domain,\n            'dmarc': dmarc_record if dmarc_record else 'Not Found'\n        })\n    \n    return jsonify({'results': results})\n\n@app.route('/api/domain_checker/dmarc_download', methods=['POST'])\n@login_required\ndef api_dmarc_download():\n    \"\"\"Generate download file for domains missing DMARC records\"\"\"\n    if not current_user.has_domain_checker_permission:\n        return jsonify({'error': 'Permission denied'}), 403\n    \n    data = request.get_json()\n    domains_text = data.get('domains', '')\n    template = data.get('template', 'v=DMARC1; p=reject; rua=mailto:postmaster@[domain]; ruf=mailto:dmarc@[domain]; fo=1; pct=100')\n    \n    domains = [d.strip().lower() for d in domains_text.strip().split('\\n') if d.strip()]\n    \n    lines = []\n    for domain in domains:\n        dmarc_record = lookup_dmarc(domain)\n        if not dmarc_record:\n            txt_value = template.replace('[domain]', domain)\n            lines.append(f\"{domain},_dmarc.{domain},TXT,{txt_value}\")\n    \n    return jsonify({'content': '\\n'.join(lines), 'count': len(lines)})\n\n@app.route('/api/domain_checker/spf_generate', methods=['POST'])\n@login_required\ndef api_spf_generate():\n    \"\"\"Generate SPF records with dual input system for domains and prefixed domains\"\"\"\n    if not current_user.has_domain_checker_permission:\n        return jsonify({'error': 'Permission denied'}), 403\n    \n    data = request.get_json()\n    domains_text = data.get('domains', '')\n    prefixed_domains_text = data.get('prefixed_domains', '')\n    ips_text = data.get('ips', '')\n    distribute = data.get('distribute', False)\n    \n    domains = [d.strip().lower() for d in domains_text.strip().split('\\n') if d.strip()]\n    prefixed_domains = [d.strip().lower() for d in prefixed_domains_text.strip().split('\\n') if d.strip()]\n    ips = [ip.strip() for ip in ips_text.strip().split('\\n') if ip.strip() and is_valid_ip(ip.strip())]\n    \n    if not domains:\n        return jsonify({'error': 'No valid domains provided'}), 400\n    if not ips:\n        return jsonify({'error': 'No valid IP addresses provided'}), 400\n    \n    if prefixed_domains and len(prefixed_domains) != len(domains):\n        return jsonify({'error': f'Number of prefixed domains ({len(prefixed_domains)}) must match number of domains ({len(domains)})'}), 400\n    \n    warning = None\n    if len(ips) > 50:\n        warning = f\"Warning: {len(ips)} IPs provided. This may exceed SPF lookup limits.\"\n    \n    lines = []\n    \n    if distribute:\n        if len(ips) < len(domains):\n            return jsonify({'error': f'Not enough IPs ({len(ips)}) to distribute among {len(domains)} domains'}), 400\n        \n        ips_per_domain = len(ips) // len(domains)\n        extra_ips = len(ips) % len(domains)\n        ip_index = 0\n        \n        for i, domain in enumerate(domains):\n            count = ips_per_domain + (1 if i < extra_ips else 0)\n            domain_ips = ips[ip_index:ip_index + count]\n            ip_index += count\n            \n            ip_parts = ' '.join([f'ip4:{ip}' for ip in domain_ips])\n            spf_record = f'v=spf1 {ip_parts} -all'\n            \n            full_domain = prefixed_domains[i] if prefixed_domains else domain\n            lines.append(f\"{domain},{full_domain},TXT,{spf_record}\")\n    else:\n        ip_parts = ' '.join([f'ip4:{ip}' for ip in ips])\n        spf_record = f'v=spf1 {ip_parts} -all'\n        \n        for i, domain in enumerate(domains):\n            full_domain = prefixed_domains[i] if prefixed_domains else domain\n            lines.append(f\"{domain},{full_domain},TXT,{spf_record}\")\n    \n    return jsonify({'content': '\\n'.join(lines), 'count': len(lines), 'warning': warning})\n\n@app.route('/api/domain_checker/a_generate', methods=['POST'])\n@login_required\ndef api_a_generate():\n    \"\"\"Generate A record entries\"\"\"\n    if not current_user.has_domain_checker_permission:\n        return jsonify({'error': 'Permission denied'}), 403\n    \n    data = request.get_json()\n    domains_text = data.get('domains', '')\n    subdomain = data.get('subdomain', '').strip()\n    ips_text = data.get('ips', '')\n    \n    if not subdomain:\n        return jsonify({'error': 'Subdomain prefix is required for A records'}), 400\n    \n    domains = [d.strip().lower() for d in domains_text.strip().split('\\n') if d.strip()]\n    ips = list(set([ip.strip() for ip in ips_text.strip().split('\\n') if ip.strip() and is_valid_ip(ip.strip())]))\n    \n    if not domains:\n        return jsonify({'error': 'No valid domains provided'}), 400\n    if not ips:\n        return jsonify({'error': 'No valid IP addresses provided'}), 400\n    \n    warning = None\n    if len(ips) > 50:\n        warning = f\"Warning: {len(ips)} unique IPs provided.\"\n    \n    lines = []\n    ips_str = ';'.join(ips)\n    \n    for domain in domains:\n        full_domain = f\"{subdomain}.{domain}\"\n        lines.append(f\"{domain},{full_domain},TXT,Arecords:{ips_str}\")\n    \n    return jsonify({'content': '\\n'.join(lines), 'count': len(lines), 'warning': warning})\n\n@app.route('/api/domain_checker/mx', methods=['POST'])\n@login_required\ndef api_mx_lookup():\n    \"\"\"API endpoint for MX lookups\"\"\"\n    if not current_user.has_domain_checker_permission:\n        return jsonify({'error': 'Permission denied'}), 403\n    \n    data = request.get_json()\n    domains_text = data.get('domains', '')\n    \n    domains = [d.strip().lower() for d in domains_text.strip().split('\\n') if d.strip()]\n    \n    results = []\n    for domain in domains:\n        mx_records = lookup_mx(domain)\n        results.append({\n            'domain': domain,\n            'mx': mx_records if mx_records else ['Not Found']\n        })\n    \n    return jsonify({'results': results})\n\n@app.route('/api/domain_checker/txt', methods=['POST'])\n@login_required\ndef api_txt_lookup():\n    \"\"\"API endpoint for TXT lookups\"\"\"\n    if not current_user.has_domain_checker_permission:\n        return jsonify({'error': 'Permission denied'}), 403\n    \n    data = request.get_json()\n    domains_text = data.get('domains', '')\n    \n    domains = [d.strip().lower() for d in domains_text.strip().split('\\n') if d.strip()]\n    \n    results = []\n    for domain in domains:\n        txt_records = lookup_txt(domain)\n        results.append({\n            'domain': domain,\n            'txt': txt_records if txt_records else ['Not Found']\n        })\n    \n    return jsonify({'results': results})\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000, debug=True)\n\napplication = app","path":null,"size_bytes":76996,"size_tokens":null},"main.py":{"content":"from app import app","path":null,"size_bytes":19,"size_tokens":null},"replit.md":{"content":"# Overview\n\nTSS Gmail Access is a Flask-based web application that provides secure, role-based access to multiple Gmail accounts through IMAP connections. The application features a comprehensive authentication system with entity-based access control, allowing different TSS entities (TSS1, TSS2, TSS3, TSSW) to access their designated Gmail accounts. Users can log in with their credentials and view email data through a clean, responsive dashboard interface.\n\n# User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n# System Architecture\n\n## Web Framework Architecture\nThe application uses Flask as the core web framework with Flask-Login for authentication and a secure MVC pattern:\n- **app.py**: Main application logic with authentication, IMAP connection handling, and email processing\n- **main.py**: Application entry point with development server configuration\n- **templates/login.html**: Secure login interface with modern design\n- **templates/dashboard.html**: Entity-specific dashboard using Jinja2 templating\n- **users.txt**: User authentication database (entity, username, password)\n- **gmailaccounts.txt**: Gmail account configuration (entity, email, app_password)\n\n## Frontend Design\n- **Responsive Design**: Built with Tailwind CSS for mobile-first responsive layout\n- **Interactive Elements**: Custom CSS animations and hover effects for enhanced user experience\n- **Icon Integration**: Font Awesome icons for visual consistency\n- **Form Handling**: JavaScript-enhanced form submission for account selection\n\n## Email Processing Architecture\n- **Optimized IMAP Integration**: Direct connection to Gmail's IMAP servers using Python's imaplib with UID-based fetching\n- **Performance Optimization**: Fetches only email headers (not full body) and limits to last 20 emails per folder maximum\n- **Client-side Filtering**: Real-time search filtering performed in browser for instant results without server requests\n- **MIME Decoding**: Custom functions for handling various email encodings and character sets\n- **Error Handling**: Comprehensive logging and error management for connection failures\n\n## Security Model\n- **Flask-Login Authentication**: Secure session management with user login/logout functionality\n- **Entity-Based Access Control**: Users can only access Gmail accounts from their assigned entity\n- **TSSW Admin Access**: TSSW users have full access to all entity Gmail accounts\n- **App Passwords**: Uses Gmail App Passwords instead of regular passwords for enhanced security\n- **File-Based User Management**: Secure user authentication from users.txt file\n- **Session Persistence**: Remember user login sessions until explicit logout\n- **Environment Variables**: Session secrets with development fallback\n\n## Data Flow\n1. User logs in with username and password from users.txt\n2. System authenticates and determines user's entity access level\n3. Dashboard displays only Gmail accounts available to user's entity\n4. User selects Gmail account from entity-filtered dropdown\n5. Application establishes IMAP connection using stored credentials from gmailaccounts.txt\n6. Email data is fetched and processed for display\n7. Results are rendered through Flask templates with comprehensive error handling\n8. User sessions persist until explicit logout\n\n# External Dependencies\n\n## Core Dependencies\n- **Flask**: Web framework for routing and templating\n- **Flask-Login**: Authentication and session management\n- **imaplib**: Python standard library for IMAP email access\n- **email**: Python standard library for email parsing and MIME handling\n\n## Frontend Dependencies\n- **Tailwind CSS**: Utility-first CSS framework loaded via CDN\n- **Font Awesome**: Icon library for UI elements loaded via CDN\n\n## Email Service Integration\n- **Gmail IMAP**: Direct integration with Gmail's IMAP servers (imap.gmail.com:993)\n- **App Passwords**: Requires Gmail App Password authentication for each account\n\n## Development Environment\n- **Python Logging**: Built-in logging for debugging and error tracking\n- **Flask Development Server**: Hot reloading enabled for development\n\n## Hosting Requirements\n- **Port Configuration**: Configured to run on port 5000 with host binding to 0.0.0.0\n- **Environment Variables**: Supports SESSION_SECRET environment variable for production security\n- **File Permissions**: Requires read access to users.txt and gmailaccounts.txt files\n\n# Entity Access Control System\n\n## User Entities\n- **TSS1**: Access to TSS1-specific Gmail accounts only\n- **TSS2**: Access to TSS2-specific Gmail accounts only  \n- **TSS3**: Access to TSS3-specific Gmail accounts only\n- **TSSF**: Access to TSSF-specific Gmail accounts only (Finance entity)\n- **TSSW**: Administrative access to all entity Gmail accounts (TSS1, TSS2, TSS3, TSSF, plus TSSW-specific accounts)\n\n## Entity Color Coding\nVisual identification in Gmail account dropdown menu:\n- **TSS1**: Blue (bg-gradient-to-br from-blue-500 to-blue-600)\n- **TSS2**: Green (bg-gradient-to-br from-green-500 to-green-600)\n- **TSS3**: Yellow (bg-gradient-to-br from-yellow-500 to-yellow-600)\n- **TSSF**: Orange (bg-gradient-to-br from-orange-500 to-orange-600)\n- **TSSW**: Red (bg-gradient-to-br from-red-500 to-red-600)\n\n## Authentication Files\n- **users.txt**: Format: `Entity,Name,Username,Password[,permissions]` (one per line)\n  - Permissions can include: \n    - `ok` (toggle permissions)\n    - `allow_add_gmail_of_news` (manage news accounts)\n    - `Domain_checker` (access Domain Checker service)\n    - `find_news` (access Find News service)\n    - `Extract_emails` (access Extract Emails service)\n  - Multiple permissions separated by comma\n- **gmailaccounts.txt**: Format: `Entity,EmailAddress,AppPassword[,news]` (one per line)\n  - Add `,news` suffix to mark accounts for the \"Find News\" service\n\n## Recent Changes (December 2025)\n\n### Performance and Permission Updates (December 8, 2025)\n-  Optimized login/logout by removing Gmail connection manager calls (faster authentication)\n-  Added new permissions: `find_news` and `Extract_emails` for service-level access control\n-  Services page now conditionally displays Find News and Extract Emails based on user permissions\n-  Route-level permission checks redirect unauthorized users to services page\n-  Domain Checker DMARC: Added filter dropdown (all/found/not_found), textarea with copy button, optional prefix input\n-  Domain Checker SPF: Dual input system for domains and prefixed domains (line-by-line matching)\n-  Domain Checker MX/TXT: Added filter dropdowns and copy button for filtered domains\n-  Find News: Fixed clipboard copy with fallback method for hosted environments\n-  Added toast-style auto-dismiss notifications positioned on right side\n\n### User Profile and Permission System (December 4, 2025)\n-  Updated users.txt format to include Name field: `entity,Name,username,password[,permissions]`\n-  Personalized user experience now displays Name in welcome messages and navigation bars\n-  Added permission system supporting multiple permissions per user (ok, allow_add_gmail_of_news)\n-  Moved \"Find News\" service to services page for easier access and organization\n-  Implemented full Gmail account management for \"Find News\" service (add/edit/delete)\n-  Permission-based account management: TSSW users can manage all entities, others limited to their own\n-  Enhanced security with entity-scoped authorization for account modifications\n\n## Recent Changes (August 2025)\n### Multi-Service Platform Implementation (August 26, 2025)\n-  Transformed application into multi-service platform with service selection dashboard\n-  Added \"TSS Gmail Access\" service (existing functionality)\n-  Implemented \"TSS Extract Emails\" service with advanced email analysis\n-  Email extraction features: SPF/DKIM status, sender IP addresses, email categorization\n-  Added filtering by domain and subject with case-insensitive matching\n-  Implemented CSV export functionality for extracted data\n-  Ensured emails remain unread during extraction process\n-  Available to all entities with any Gmail credentials (not entity-restricted)\n\n### TSSF Entity Integration and Color Coding System (August 26, 2025)\n-  Added new TSSF entity (Finance) with same access control as TSS1/TSS2/TSS3\n-  Updated TSSW access to include TSSF accounts alongside TSS1/TSS2/TSS3\n-  Implemented entity-based color coding system in Gmail account dropdown\n-  Added example TSSF Gmail accounts and users to configuration files\n-  Enhanced visual identification with gradient color scheme\n\n### Migration to Replit Environment  \n-  Successfully migrated from Replit Agent to standard Replit environment\n-  Installed all required dependencies (Flask, Flask-Login, gunicorn, etc.)\n-  Configured proper port binding and server settings\n-  Created PostgreSQL database for future expansion\n\n### Enhanced Entity-Based Connection System (August 17, 2025)\n-  Implemented entity-based connection pooling - when one user from an entity logs in, ALL Gmail accounts for that entity connect automatically\n-  Added smart connection management - connections only exist when entity has active users\n-  Enhanced TSSW admin functionality - TSSW users trigger connections to ALL entities\n-  Optimized for multiple concurrent users per entity sharing the same Gmail connections\n-  Eliminated per-user connection overhead - connections are now shared at entity level\n-  Improved real-time email updates with entity-based monitoring threads\n-  Added automatic cleanup when last user from entity logs out\n\n### Real-time Email System Implementation\n-  Implemented advanced connection pooling system for efficient IMAP connections\n-  Added persistent Gmail connections shared among multiple users\n-  Created Server-Sent Events (SSE) for real-time email updates in browser\n-  Implemented automatic connection management (connects when users join, disconnects when no users)\n-  Added reliable polling system (every 10 seconds) replacing problematic IDLE implementation\n-  Fixed Gmail folder categorization using cached category searches\n-  Enhanced email fetching to get 50 most recent emails from Inbox and Spam folders\n-  Improved error handling and automatic reconnection for dropped connections\n-  Optimized performance to handle 10+ concurrent users efficiently\n\n### Previous Features (January 2025)\n-  Implemented Flask-Login authentication system\n-  Added entity-based access control for Gmail accounts\n-  Created secure login interface with modern design\n-  Developed entity-specific dashboard with user info display\n-  Added persistent session management with remember me functionality\n-  Implemented file-based user and Gmail account management\n-  Added TSSW administrative access to all entities\n-  Enhanced security with proper logout functionality\n-  Added Gmail folder categorization (Primary, Promotions, Social, Updates, Forums, Spam)\n-  Created color-coded folder badges for visual distinction\n-  Added folder type filtering with dropdown selection\n-  Enhanced client-side filtering for instant search results\n-  Created responsive table layout with separate columns for better readability\n-  Enhanced mobile responsiveness with adaptive column display","path":null,"size_bytes":11346,"size_tokens":null},"HOSTING_INSTRUCTIONS.md":{"content":"# Hosting TSS Gmail Access on Namecheap\n\n## Prerequisites\n1. Namecheap shared hosting account\n2. Domain name (already registered)\n3. Access to cPanel\n\n## Step 1: Prepare Your Files\n1. Download all project files from Replit\n2. Create a zip file containing:\n   - `app.py` (main application)\n   - `main.py` (entry point)\n   - `templates/` folder (with login.html and dashboard.html)\n   - `static/` folder (with style.css if any)\n   - `users.txt` (user authentication file)\n   - `gmailaccounts.txt` (Gmail account configuration)\n   - `requirements.txt` (create this file - see below)\n\n## Step 2: Create requirements.txt\nCreate a file named `requirements.txt` with the following content:\n```\nFlask==2.3.3\nFlask-Login==0.6.3\ngunicorn==21.2.0\n```\n\n## Step 3: Upload to Namecheap\n1. Log into your Namecheap cPanel\n2. Go to **File Manager**\n3. Navigate to `public_html` folder\n4. Upload and extract your project files\n5. Make sure the files are in the root directory or a subdirectory\n\n## Step 4: Python Setup on Namecheap\n### For Shared Hosting:\n1. Go to **Python App** in cPanel\n2. Click \"Create Application\"\n3. Select Python version (3.8 or higher)\n4. Set application URL (your domain or subdomain)\n5. Set application root to where you uploaded files\n6. Set startup file as `main.py`\n7. Click \"Create\"\n\n### Install Dependencies:\n1. In Python App interface, open \"Virtual Environment\"\n2. Run: `pip install -r requirements.txt`\n\n## Step 5: Environment Configuration\n1. In Python App settings, add environment variables:\n   - `SESSION_SECRET`: Generate a random secret key (use online generator)\n   - `FLASK_ENV`: production\n\n## Step 6: File Permissions\nEnsure these files have correct permissions:\n- `users.txt`: 644 (readable by web server)\n- `gmailaccounts.txt`: 644 (readable by web server)\n- `app.py`: 644\n- `main.py`: 644\n\n## Step 7: Update Gmail App Passwords\nMake sure all Gmail accounts in `gmailaccounts.txt` have:\n1. 2-factor authentication enabled\n2. App passwords generated specifically for this application\n3. \"Less secure app access\" is NOT needed (we use app passwords)\n\n## Step 8: Test the Application\n1. Visit your domain\n2. Test login with credentials from `users.txt`\n3. Test email fetching functionality\n4. Verify all filters and auto-refresh work\n\n## Troubleshooting\n\n### Common Issues:\n1. **500 Internal Server Error**\n   - Check Python app logs in cPanel\n   - Verify all dependencies are installed\n   - Check file permissions\n\n2. **Gmail Connection Failed**\n   - Verify app passwords are correct\n   - Check Gmail accounts have 2FA enabled\n   - Ensure Gmail accounts are not locked\n\n3. **Login Issues**\n   - Verify `users.txt` format: `Entity,Username,Password`\n   - Check file permissions\n   - Verify SESSION_SECRET is set\n\n### Log Files:\n- Check Python app error logs in cPanel\n- Monitor access logs for any issues\n\n## Security Notes\n1. Keep `users.txt` and `gmailaccounts.txt` secure\n2. Use strong passwords\n3. Regularly update Gmail app passwords\n4. Monitor access logs\n5. Consider using HTTPS (SSL certificate)\n\n## Alternative: VPS Hosting\nIf shared hosting doesn't work well, consider Namecheap VPS:\n1. Get a VPS plan\n2. Install Python 3.8+\n3. Install nginx or Apache\n4. Use systemd to run the Flask app\n5. Set up reverse proxy\n\n## File Structure Example:\n```\npublic_html/\n app.py\n main.py\n requirements.txt\n users.txt\n gmailaccounts.txt\n templates/\n    login.html\n    dashboard.html\n static/\n     style.css\n```\n\n## Support\n- Contact Namecheap support for Python app setup issues\n- Check Namecheap knowledge base for Python hosting guides\n- Ensure your hosting plan supports Python applications","path":null,"size_bytes":3710,"size_tokens":null}},"version":2}